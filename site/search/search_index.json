{"config":{"lang":["en","ja"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"cli/","title":"CLI Usage","text":"<p>\u521d\u56de\u306e\u5b9f\u884c\u6642\u306e\u307f, HuggingFaseHub \u304b\u3089\u30e2\u30c7\u30eb\u306e\u91cd\u307f\u30d5\u30a1\u30a4\u30eb\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u307e\u3059\u3002 \u4ee5\u4e0b\u306e\u30b3\u30de\u30f3\u30c9\u306b\u3066\u3001\u6587\u66f8\u753b\u50cf\u306e\u89e3\u6790\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002</p> <pre><code>yomitoku ${path_data} -v -o results\n</code></pre> <ul> <li><code>${path_data}</code> \u89e3\u6790\u5bfe\u8c61\u306e\u753b\u50cf\u304c\u542b\u307e\u308c\u305f\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u304b\u753b\u50cf\u30d5\u30a1\u30a4\u30eb\u306e\u30d1\u30b9\u3092\u76f4\u63a5\u3057\u3066\u6307\u5b9a\u3057\u3066\u304f\u3060\u3055\u3044\u3002\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3092\u5bfe\u8c61\u3068\u3057\u305f\u5834\u5408\u306f\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306e\u30b5\u30d6\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u5185\u306e\u753b\u50cf\u3082\u542b\u3081\u3066\u51e6\u7406\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002\u30d5\u30a1\u30a4\u30eb\u5f62\u5f0f\u306f pdf, jpeg, png, bmp, tiff \u3092\u30b5\u30dd\u30fc\u30c8\u3057\u3066\u3044\u307e\u3059\u3002</li> <li><code>-o</code>, <code>--outdir</code> \u51fa\u529b\u5148\u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u540d\u3092\u6307\u5b9a\u3057\u307e\u3059\u3002\u5b58\u5728\u3057\u306a\u3044\u5834\u5408\u306f\u65b0\u898f\u3067\u4f5c\u6210\u3055\u308c\u307e\u3059\u3002</li> <li><code>-v</code>, <code>--vis</code> \u3092\u6307\u5b9a\u3059\u308b\u3068\u89e3\u6790\u7d50\u679c\u3092\u53ef\u8996\u5316\u3057\u305f\u753b\u50cf\u3092\u51fa\u529b\u3057\u307e\u3059\u3002</li> </ul> <p>Note:</p> <ul> <li>\u6d3b\u5b57\u306e\u307f\u306e\u8b58\u5225\u3092\u30b5\u30dd\u30fc\u30c8\u3057\u3066\u304a\u308a\u307e\u3059\u3002\u624b\u66f8\u304d\u6587\u5b57\u306b\u95a2\u3057\u3066\u306f\u3001\u8aad\u307f\u53d6\u308c\u308b\u5834\u5408\u3082\u3042\u308a\u307e\u3059\u304c\u3001\u516c\u5f0f\u306b\u306f\u30b5\u30dd\u30fc\u30c8\u3057\u3066\u304a\u308a\u307e\u305b\u3093\u3002</li> <li>OCR \u306f\u6587\u66f8 OCR \u3068\u60c5\u666f OCR(\u770b\u677f\u306a\u3069\u7d19\u4ee5\u5916\u306b\u30d7\u30ea\u30f3\u30c8\u3055\u308c\u305f\u6587\u5b57)\u306b\u5927\u5225\u3055\u308c\u307e\u3059\u304c\u3001Yomitoku \u306f\u6587\u66f8 OCR \u5411\u3051\u306b\u6700\u9069\u5316\u3055\u308c\u3066\u3044\u307e\u3059\u3002</li> <li>AI-OCR \u306e\u8b58\u5225\u7cbe\u5ea6\u3092\u9ad8\u3081\u308b\u305f\u3081\u306b\u3001\u5165\u529b\u753b\u50cf\u306e\u89e3\u50cf\u5ea6\u304c\u91cd\u8981\u3067\u3059\u3002\u4f4e\u89e3\u50cf\u5ea6\u753b\u50cf\u3067\u306f\u8b58\u5225\u7cbe\u5ea6\u304c\u4f4e\u4e0b\u3057\u307e\u3059\u3002\u753b\u50cf\u306e\u77ed\u8fba\u3092 1000px \u4ee5\u4e0a\u306e\u753b\u50cf\u3067\u63a8\u8ad6\u3059\u308b\u3053\u3068\u3092\u304a\u52e7\u3081\u3057\u307e\u3059\u3002</li> </ul>"},{"location":"cli/#_1","title":"\u30d8\u30eb\u30d7\u306e\u53c2\u7167","text":"<p><code>--help</code>, <code>-h</code>\u306b\u3066 CLI \u306b\u6307\u5b9a\u53ef\u80fd\u306a\u30aa\u30d7\u30b7\u30e7\u30f3\u3092\u8868\u793a\u3057\u307e\u3059\u3002</p>"},{"location":"cli/#_2","title":"\u8efd\u91cf\u30e2\u30fc\u30c9\u3067\u306e\u5b9f\u884c","text":"<p><code>--lite</code>\u30aa\u30d7\u30b7\u30e7\u30f3\u3092\u4ed8\u4e0e\u3059\u308b\u3053\u3068\u3067\u3001\u8efd\u91cf\u30e2\u30c7\u30eb\u3092\u4f7f\u7528\u3057\u3066\u3001\u63a8\u8ad6\u3059\u308b\u3053\u3068\u304c\u53ef\u80fd\u3067\u3059\u3002\u901a\u5e38\u30e2\u30fc\u30c9\u3088\u308a\u9ad8\u901f\u306b\u89e3\u6790\u304c\u5b9f\u884c\u53ef\u80fd\u3067\u3059\u3002\u305f\u3060\u3057\u3001\u6587\u5b57\u306e\u8a8d\u8b58\u7cbe\u5ea6\u304c\u4f4e\u4e0b\u3059\u308b\u53ef\u80fd\u6027\u304c\u3042\u308a\u307e\u3059\u3002</p> <pre><code>yomitoku ${path_data} --lite -v\n</code></pre>"},{"location":"cli/#_3","title":"\u51fa\u529b\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u306e\u6307\u5b9a","text":"<ul> <li><code>-f</code>, <code>--format</code> \u51fa\u529b\u5f62\u5f0f\u306e\u30d5\u30a1\u30a4\u30eb\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3092\u6307\u5b9a\u3057\u307e\u3059\u3002(json, csv, html, md, pdf(searchable-pdf) \u3092\u30b5\u30dd\u30fc\u30c8)</li> </ul> <pre><code>yomitoku ${path_data} -f md\n</code></pre> <ul> <li>pdf: \u753b\u50cf\u5185\u306e\u6587\u5b57\u60c5\u5831\u3092\u8a8d\u8b58\u3057\u3001\u6587\u5b57\u60c5\u5831\u3092\u900f\u660e\u30c6\u30ad\u30b9\u30c8\u3068\u3057\u3066\u3001PDF\u306b\u57cb\u3081\u8fbc\u3080\u3053\u3068\u3067\u3001\u30b5\u30fc\u30c1\u30e3\u30d6\u30ebPDF\u306b\u5909\u63db\u3057\u307e\u3059\u3002</li> </ul>"},{"location":"cli/#_4","title":"\u51fa\u529b\u30c7\u30d0\u30a4\u30b9\u306e\u6307\u5b9a","text":"<ul> <li><code>-d</code>, <code>--device</code> \u30aa\u30d7\u30b7\u30e7\u30f3\u3092\u4f7f\u7528\u3059\u308b\u3053\u3068\u3067\u3001\u30e2\u30c7\u30eb\u3092\u5b9f\u884c\u3059\u308b\u305f\u3081\u306e\u30c7\u30d0\u30a4\u30b9\u3092\u6307\u5b9a\u3057\u307e\u3059\u3002(cuda | cpu | mps)\u3002gpu \u304c\u5229\u7528\u3067\u304d\u306a\u3044\u5834\u5408\u306f cpu \u3067\u63a8\u8ad6\u304c\u5b9f\u884c\u3055\u308c\u307e\u3059\u3002(\u30c7\u30d5\u30a9\u30eb\u30c8: cuda)</li> </ul> <pre><code>yomitoku ${path_data} -d cpu\n</code></pre>"},{"location":"cli/#_5","title":"\u6539\u884c\u306e\u7121\u8996","text":"<p>\u901a\u5e38\u30e2\u30fc\u30c9\u3067\u306f\u3001\u753b\u50cf\u5185\u3067\u8a18\u8ff0\u3055\u308c\u305f\u60c5\u5831\u306b\u5f93\u3044\u3001\u6539\u884c\u3092\u884c\u3044\u307e\u3059\u3002 <code>--ignore_line_break</code> \u30aa\u30d7\u30b7\u30e7\u30f3\u3092\u4f7f\u7528\u3059\u308b\u3053\u3068\u3067\u3001\u753b\u50cf\u306e\u6539\u884c\u4f4d\u7f6e\u3092\u7121\u8996\u3057\u3066\u3001\u6bb5\u843d\u5185\u306e\u540c\u4e00\u6587\u7ae0\u3092\u9023\u7d50\u3057\u3066\u8fd4\u3059\u3053\u3068\u304c\u53ef\u80fd\u3067\u3059\u3002</p> <pre><code>yomitoku ${path_data} --ignore_line_break\n</code></pre>"},{"location":"cli/#_6","title":"\u56f3\u3084\u30b0\u30e9\u30d5\u753b\u50cf\u306e\u51fa\u529b","text":"<p>\u901a\u5e38\u30e2\u30fc\u30c9\u3067\u306f\u3001\u6587\u66f8\u753b\u50cf\u5185\u306e\u542b\u307e\u308c\u308b\u56f3\u3084\u753b\u50cf\u306e\u60c5\u5831\u3092\u51fa\u529b\u3057\u307e\u305b\u3093\u3002<code>--figure</code>\u30aa\u30d7\u30b7\u30e7\u30f3\u3092\u4f7f\u7528\u3059\u308b\u3053\u3068\u3067\u3001\u6587\u66f8\u753b\u50cf\u306b\u542b\u307e\u308c\u308b\u3001\u56f3\u3084\u753b\u50cf\u3092\u5207\u308a\u51fa\u3057\u3001\u500b\u5225\u306e\u753b\u50cf\u3068\u3057\u3066\u4fdd\u5b58\u3001\u307e\u305f\u3001\u51fa\u529b\u30d5\u30a1\u30a4\u30eb\u5185\u306b\u691c\u51fa\u3057\u305f\u500b\u5225\u306e\u753b\u50cf\u306b\u5bfe\u3059\u308b\u30ea\u30f3\u30af\u3092\u51fa\u529b\u3057\u307e\u3059\u3002</p> <pre><code>yomitoku ${path_data} --figure\n</code></pre>"},{"location":"cli/#_7","title":"\u56f3\u3084\u753b\u50cf\u5185\u306b\u542b\u307e\u308c\u308b\u6587\u5b57\u306e\u51fa\u529b","text":"<p>\u901a\u5e38\u30e2\u30fc\u30c9\u3067\u306f\u3001\u56f3\u3084\u753b\u50cf\u5185\u306b\u542b\u307e\u308c\u308b\u6587\u5b57\u60c5\u5831\u306f\u51fa\u529b\u30d5\u30a1\u30a4\u30eb\u306b\u51fa\u529b\u3057\u307e\u305b\u3093\u3002 <code>--figure_letter</code> \u30aa\u30d7\u30b7\u30e7\u30f3\u3092\u4f7f\u7528\u3059\u308b\u3053\u3068\u3067\u3001\u753b\u50cf\u3084\u56f3\u306b\u542b\u307e\u308c\u308b\u6587\u5b57\u60c5\u5831\u3082\u51fa\u529b\u30d5\u30a1\u30a4\u30eb\u306b\u51fa\u529b\u3057\u307e\u3059\u3002</p> <pre><code>yomitoku ${path_data} --figure_letter\n</code></pre>"},{"location":"cli/#_8","title":"\u51fa\u529b\u30d5\u30a1\u30a4\u30eb\u306e\u6587\u5b57\u30b3\u30fc\u30c9\u306e\u6307\u5b9a","text":"<p>\u51fa\u529b\u30d5\u30a1\u30a4\u30eb\u306e\u6587\u5b57\u30b3\u30fc\u30c9\u3092<code>--encoding</code>\u30aa\u30d7\u30b7\u30e7\u30f3\u306b\u3066\u6307\u5b9a\u3067\u304d\u307e\u3059\u3002(utf-8, utf-8-sig, shift-jis, enc-jp, cp932)\u3002\u30b5\u30dd\u30fc\u30c8\u3055\u308c\u3066\u3044\u306a\u3044\u6587\u5b57\u30b3\u30fc\u30c9\u304c\u542b\u307e\u308c\u308b\u5834\u5408\u306f\u3001\u305d\u306e\u6587\u5b57\u3092\u7121\u8996\u3057\u3001\u51fa\u529b\u3057\u307e\u305b\u3093\u3002</p> <pre><code>yomitoku ${path_data} --encoding utf-8-sig\n</code></pre>"},{"location":"cli/#_9","title":"\u30b3\u30f3\u30d5\u30a3\u30b0\u306e\u30d1\u30b9\u306e\u6307\u5b9a","text":"<p>\u5404\u30e2\u30b8\u30e5\u30fc\u30eb\u306b\u5bfe\u3059\u308b config \u30d5\u30a1\u30a4\u30eb\u306e\u30d1\u30b9\u3092\u6307\u5b9a\u3057\u307e\u3059\u3002</p> <ul> <li><code>--td_cfg</code>: Text Detector \u306b\u5bfe\u3059\u308b config \u304c\u8a18\u8ff0\u3055\u308c\u305f yaml \u30d5\u30a1\u30a4\u30eb\u306b\u5bfe\u3059\u308b\u30d1\u30b9</li> <li><code>--tr_cfg</code>: Text Recognizer \u306b\u5bfe\u3059\u308b config \u304c\u8a18\u8ff0\u3055\u308c\u305f yaml \u30d5\u30a1\u30a4\u30eb\u306b\u5bfe\u3059\u308b\u30d1\u30b9</li> <li><code>--lp_cfg</code>: Layout Parser \u306b\u5bfe\u3059\u308b config \u304c\u8a18\u8ff0\u3055\u308c\u305f yaml \u30d5\u30a1\u30a4\u30eb\u306b\u5bfe\u3059\u308b\u30d1\u30b9</li> <li><code>--tsr_cfg</code>: Table Structure Recognizer \u306b\u5bfe\u3059\u308b config \u304c\u8a18\u8ff0\u3055\u308c\u305f yaml \u30d5\u30a1\u30a4\u30eb\u306b\u5bfe\u3059\u308b\u30d1\u30b9</li> </ul> <pre><code>yomitoku ${path_data} --td_cfg ${path_yaml}\n</code></pre>"},{"location":"cli/#_10","title":"\u30e1\u30bf\u60c5\u5831\u3092\u51fa\u529b\u30d5\u30a1\u30a4\u30eb\u306b\u52a0\u3048\u306a\u3044","text":"<p>\u30d8\u30c3\u30c0\u30fc\u3084\u30d5\u30c3\u30bf\u30fc\u7b49\u306e\u30e1\u30bf\u30c7\u30fc\u30bf\u3092\u51fa\u529b\u30d5\u30a1\u30a4\u30eb\u306b\u52a0\u3048\u306a\u3044\u3088\u3046\u306b\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002</p> <pre><code>yomitoku ${path_data} --ignore_meta\n</code></pre>"},{"location":"cli/#_11","title":"\u8907\u6570\u30da\u30fc\u30b8\u3092\u7d71\u5408\u3059\u308b","text":"<p>PDF\u306b\u8907\u6570\u30da\u30fc\u30b8\u304c\u542b\u307e\u308c\u308b\u5834\u5408\u306b\u8907\u6570\u30da\u30fc\u30b8\u3092\u4e00\u3064\u306e\u30d5\u30a1\u30a4\u30eb\u306b\u307e\u3068\u3081\u3066\u30a8\u30af\u30b9\u30dd\u30fc\u30c8\u3067\u304d\u307e\u3059\u3002</p> <pre><code>yomitoku ${path_data} -f md --combine\n</code></pre>"},{"location":"cli/#pdf","title":"PDF\u306e\u8aad\u307f\u53d6\u308a\u89e3\u50cf\u5ea6\u306e\u8a2d\u5b9a","text":"<p>PDF\u3092\u8aad\u307f\u53d6\u308b\u969b\u306e\u89e3\u50cf\u5ea6\u306e\u5927\u304d\u3055\u3092\u8a2d\u5b9a\u3057\u307e\u3059(\u6a19\u6e96DPI=200)\u3002PDF\u5185\u306e\u6587\u5b57\u304c\u5fae\u7d30\u306a\u5834\u5408\u306a\u3069\u3001\u7d30\u90e8\u306e\u6587\u5b57\u3092\u8aad\u307f\u53d6\u308a\u305f\u3044\u5834\u5408\u306bDPI\u5024\u3092\u4e0a\u3052\u308b\u3053\u3068\u3067\u8aad\u307f\u53d6\u308a\u7cbe\u5ea6\u304c\u5411\u4e0a\u3059\u308b\u5834\u5408\u304c\u3042\u308a\u307e\u3059\u3002</p> <pre><code>yomitoku ${path_data} --dpi 250\n</code></pre>"},{"location":"cli/#_12","title":"\u8aad\u307f\u53d6\u308a\u9806\u3092\u6307\u5b9a\u3059\u308b","text":"<p>Auto\u3067\u306f\u3001\u6a2a\u66f8\u304d\u306e\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u3001\u7e26\u66f8\u304d\u306e\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u3092\u8b58\u5225\u3057\u3001\u81ea\u52d5\u3067\u8aad\u307f\u53d6\u308a\u9806\u3092\u63a8\u5b9a\u3057\u307e\u3059\u304c\u3001\u4efb\u610f\u306e\u8aad\u307f\u53d6\u308a\u9806\u306e\u6307\u5b9a\u3059\u308b\u3053\u3068\u304c\u53ef\u80fd\u3067\u3059\u3002\u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u306f\u6a2a\u66f8\u304d\u306e\u6587\u66f8\u306f<code>top2left</code>, \u7e26\u66f8\u304d\u306f<code>top2bottom</code>\u306b\u306a\u308a\u307e\u3059\u3002</p> <pre><code>yomitoku ${path_data} --reading_order left2right\n</code></pre> <ul> <li> <p><code>top2bottom</code>: \u4e0a\u304b\u3089\u4e0b\u65b9\u5411\u306b\u512a\u5148\u7684\u306b\u8aad\u307f\u53d6\u308a\u9806\u3092\u63a8\u5b9a\u3057\u307e\u3059\u3002\u6bb5\u7d44\u307f\u306e\u30ef\u30fc\u30c9\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306a\u3069\u306b\u5bfe\u3057\u3066\u3001\u6709\u52b9\u3067\u3059\u3002</p> </li> <li> <p><code>left2right</code>: \u5de6\u304b\u3089\u53f3\u65b9\u5411\u306b\u512a\u5148\u7684\u306b\u8aad\u307f\u53d6\u308a\u9806\u3092\u63a8\u5b9a\u3057\u307e\u3059\u3002\u30ec\u30b7\u30fc\u30c8\u3084\u4fdd\u967a\u8a3c\u306a\u3069\u30ad\u30fc\u306b\u5bfe\u3057\u3066\u3001\u5024\u3092\u793a\u3059\u30c6\u30ad\u30b9\u30c8\u304c\u6bb5\u7d44\u307f\u306b\u306a\u3063\u3066\u3044\u308b\u3088\u3046\u306a\u30ec\u30a4\u30a2\u30a6\u30c8\u306b\u6709\u52b9\u3067\u3059\u3002</p> </li> <li> <p><code>right2left:</code> \u53f3\u304b\u3089\u5de6\u65b9\u5411\u306b\u512a\u5148\u7684\u306b\u8aad\u307f\u53d6\u308a\u9806\u3092\u63a8\u5b9a\u3057\u307e\u3059\u3002\u7e26\u66f8\u304d\u306e\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u306b\u5bfe\u3057\u3066\u6709\u52b9\u3067\u3059\u3002</p> </li> </ul>"},{"location":"cli/#_13","title":"\u8aad\u307f\u53d6\u308a\u5bfe\u8c61\u30da\u30fc\u30b8\u3092\u6307\u5b9a\u3059\u308b","text":"<p>\u7279\u5b9a\u306e\u30da\u30fc\u30b8\u306e\u307f\u3092\u5bfe\u8c61\u3068\u3057\u3066\u51e6\u7406\u3059\u308b\u3053\u3068\u304c\u53ef\u80fd\u3067\u3059\u3002\u51e6\u7406\u5bfe\u8c61\u306e\u30da\u30fc\u30b8\u3092\u30b3\u30f3\u30de\u533a\u5207\u308a\u3082\u3057\u304f\u306f\u3001\u30cf\u30a4\u30d5\u30f3\u306b\u3088\u3063\u3066\u9023\u7d9a\u3059\u308b\u30da\u30fc\u30b8\u3092\u6307\u5b9a\u3067\u304d\u307e\u3059\u3002</p> <pre><code>yomitoku ${path_data} --pages 1,3-5,10\n</code></pre>"},{"location":"configuration/","title":"Configuration","text":"<p>\u5404\u30e2\u30b8\u30e5\u30fc\u30eb\u306b\u5bfe\u3057\u3066\u3001\u8a2d\u5b9a\u53ef\u80fd\u306a\u30d1\u30e9\u30e1\u30fc\u30bf\u306b\u3064\u3044\u3066\u8aac\u660e\u3057\u307e\u3059\u3002</p>"},{"location":"configuration/#text-detector","title":"Text Detector","text":""},{"location":"configuration/#_1","title":"\u5165\u529b\u753b\u50cf\u30b5\u30a4\u30ba\u306b\u95a2\u3059\u308b\u8a2d\u5b9a","text":"<pre><code>data:\n  # \u753b\u50cf\u306e\u77ed\u8fba\u30d4\u30af\u30bb\u30eb\u6570\u304c\u8a2d\u5b9a\u3057\u305f\u6570\u5024\u3092\u4e0b\u56de\u308b\u5834\u5408\u306b\u3053\u3053\u3067\u8a2d\u5b9a\u3057\u305f\u753b\u50cf\u306e\u30d4\u30af\u30bb\u30eb\u6570\u306b\u4ee5\u4e0a\u306b\u306a\u308b\u3088\u3046\u306b\u753b\u50cf\u3092\u62e1\u5927\u3057\u307e\u3059\u3002\n  shortest_size: int \n\n  #\u753b\u50cf\u306e\u9577\u8fba\u30d4\u30af\u30bb\u30eb\u6570\u304c\u8a2d\u5b9a\u3057\u305f\u6570\u5024\u3092\u4e0a\u56de\u308b\u5834\u5408\u306b\u3053\u3053\u3067\u8a2d\u5b9a\u3057\u305f\u753b\u50cf\u306e\u30d4\u30af\u30bb\u30eb\u6570\u4ee5\u4e0b\u306b\u306a\u308b\u3088\u3046\u306b\u753b\u50cf\u3092\u7e2e\u5c0f\u3057\u307e\u3059\u3002\n  limit_size: int \n</code></pre>"},{"location":"configuration/#_2","title":"\u5f8c\u51e6\u7406","text":"<pre><code>post_process:\n  #\u691c\u51fa\u3057\u305f\u9818\u57df\u306e\u8fba\u306e\u5927\u304d\u3044\u3055\u304c\u8a2d\u5b9a\u3057\u305f\u6570\u5024\u3092\u4e0b\u56de\u308b\u5834\u5408\u306b\u9818\u57df\u3092\u9664\u53bb\u3057\u307e\u3059\u3002\n  min_size: int \n\n  #\u30e2\u30c7\u30eb\u306e\u4e88\u6e2c\u30b9\u30b3\u30a2\u306b\u5bfe\u3059\u308b\u95be\u5024\u3067\u3001\u4e88\u6e2c\u30b9\u30b3\u30a2\u304c\u8a2d\u5b9a\u3057\u305f\u95be\u5024\u3092\u4e0b\u56de\u308b\u30d4\u30af\u30bb\u30eb\u3092\u80cc\u666f\u9818\u57df\u3068\u3057\u3066\u6271\u3044\u307e\u3059\u3002\n  thresh: float \n\n  #\u9818\u57df\u5185\u306e\u4e88\u6e2c\u306e\u5e73\u5747\u30b9\u30b3\u30a2\u306b\u5bfe\u3059\u308b\u95be\u5024\u3067\u3001\u95be\u5024\u3092\u4e0b\u56de\u308b\u9818\u57df\u3092\u9664\u5916\u3059\u308b\n  box_thresh: float \n\n  #\u691c\u51fa\u53ef\u80fd\u306a\u30c6\u30ad\u30b9\u30c8\u9818\u57df\u6570\u306e\u4e0a\u9650\n  max_candidates: int \n\n  #\u30c6\u30ad\u30b9\u30c8\u9818\u57df\u306e\u30de\u30fc\u30b8\u30f3\u9818\u57df\u306e\u5927\u304d\u3055\u3092\u8a2d\u5b9a\u3059\u308b\u305f\u3081\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3002\u5927\u304d\u3044\u307b\u3069\u3001\u30c6\u30ad\u30b9\u30c8\u9818\u57df\u306e\u30de\u30fc\u30b8\u30f3\u3092\u5927\u304d\u304f\u3057\u3001\u4f59\u767d\u3092\u6301\u305f\u305b\u305f\u691c\u51fa\u304c\u53ef\u80fd\u306b\u306a\u308a\u3001\u5c0f\u3055\u3044\u307b\u3069\u30bf\u30a4\u30c8\u306a\u691c\u51fa\u306b\u306a\u308b\u3002\n  unclip_ratio: int \n</code></pre>"},{"location":"configuration/#_3","title":"\u53ef\u8996\u5316\u8a2d\u5b9a","text":"<pre><code>visualize:\n  #\u691c\u51fa\u9818\u57df\u306e\u30d0\u30a6\u30f3\u30c7\u30a3\u30f3\u30b0\u30dc\u30c3\u30af\u30b9\u306e\u8272\u306e\u8a2d\u5b9a\n  color: [B, G, R] \n\n  #\u30e2\u30c7\u30eb\u306e\u4e88\u6e2c\u30d2\u30fc\u30c8\u30de\u30c3\u30d7\u3092\u53ef\u8996\u5316\u3001\u63cf\u753b\u3059\u308b\u304b\n  heatmap: boolean \n</code></pre>"},{"location":"configuration/#text-recognizer","title":"Text Recognizer","text":""},{"location":"configuration/#_4","title":"\u6587\u5b57\u5217\u9577","text":"<pre><code>#\u4e88\u6e2c\u53ef\u80fd\u306a\u6700\u5927\u6587\u5b57\u5217\u9577\nmax_label_length: int\n</code></pre>"},{"location":"configuration/#_5","title":"\u5165\u529b\u753b\u50cf","text":"<pre><code>data:\n   #\u30d0\u30c3\u30c1\u51e6\u7406\u306b\u7528\u3044\u308b\u753b\u50cf\u6570\n  batch_size: int\n</code></pre>"},{"location":"configuration/#_6","title":"\u53ef\u8996\u5316\u8a2d\u5b9a","text":"<pre><code>visualize:\n  # \u4e88\u6e2c\u7d50\u679c\u6587\u5b57\u5217\u306e\u53ef\u8996\u5316\u306b\u7528\u3044\u308b\u30d5\u30a9\u30f3\u30c8\u306e\u30d1\u30b9\n  font: str \n\n  # \u4e88\u6e2c\u7d50\u679c\u6587\u5b57\u5217\u306e\u53ef\u8996\u5316\u306b\u7528\u3044\u308b\u30d5\u30a9\u30f3\u30c8\u306e\u8272\n  color: [BGR] \n\n  # \u4e88\u6e2c\u7d50\u679c\u6587\u5b57\u5217\u306e\u30d5\u30a9\u30f3\u30c8\u306e\u5927\u304d\u3055\n  font_size: int\n</code></pre>"},{"location":"configuration/#layout_parser","title":"Layout_parser","text":""},{"location":"configuration/#_7","title":"\u4e88\u6e2c\u30b9\u30b3\u30a2\u306b\u5bfe\u3059\u308b\u95be\u5024","text":"<pre><code>#\u30e2\u30c7\u30eb\u306e\u4e88\u6e2c\u30b9\u30b3\u30a2\u306b\u5bfe\u3059\u308b\u95be\u5024\u3067\u3001\u4e88\u6e2c\u30b9\u30b3\u30a2\u304c\u8a2d\u5b9a\u3057\u305f\u95be\u5024\u3092\u9818\u57df\u3092\u9664\u5916\u3057\u307e\u3059\u3002\nthresh_score: float \n</code></pre>"},{"location":"configuration/#table-structure-recognizer","title":"Table Structure Recognizer","text":""},{"location":"configuration/#_8","title":"\u4e88\u6e2c\u30b9\u30b3\u30a2\u306b\u5bfe\u3059\u308b\u95be\u5024","text":"<pre><code>#\u30e2\u30c7\u30eb\u306e\u4e88\u6e2c\u30b9\u30b3\u30a2\u306b\u5bfe\u3059\u308b\u95be\u5024\u3067\u3001\u4e88\u6e2c\u30b9\u30b3\u30a2\u304c\u8a2d\u5b9a\u3057\u305f\u95be\u5024\u3092\u9818\u57df\u3092\u9664\u5916\u3057\u307e\u3059\u3002\nthresh_score: float \n</code></pre>"},{"location":"document_analyzer_schema/","title":"Document Analyzer","text":"DocumentAnalyzerSchema DocumentAnalyzerSchemaType: object No Additional Properties paragraphs Required root          paragraphsParagraphsType: array <p>List of detected paragraphs</p> No Additional ItemsEach item of this array must be: root          paragraphs ParagraphSchemaParagraphSchemaType: object No Additional Properties box Required root          paragraphs ParagraphSchema boxBoxType: array of integer <p>Bounding box of the paragraph in the format [x1, y1, x2, y2]</p> <p>Must contain a minimum of <code>4</code> items</p><p>Must contain a maximum of <code>4</code> items</p> No Additional ItemsEach item of this array must be: root          paragraphs ParagraphSchema box box itemsType: integer contents Required root          paragraphs ParagraphSchema contentsContents <p>Text content of the paragraph</p> Any of <ul><li> Option 1 </li><li> Option 2 </li></ul> root          paragraphs ParagraphSchema contents anyOf item 0Type: string root          paragraphs ParagraphSchema contents anyOf item 1Type: null direction Required root          paragraphs ParagraphSchema directionDirection <p>Text direction, e.g., ['horizontal' or 'vertical']</p> Any of <ul><li> Option 1 </li><li> Option 2 </li></ul> root          paragraphs ParagraphSchema direction anyOf item 0Type: string root          paragraphs ParagraphSchema direction anyOf item 1Type: null order Required root          paragraphs ParagraphSchema orderOrder <p>Order of the paragraph in the document</p> Any of <ul><li> Option 1 </li><li> Option 2 </li></ul> root          paragraphs ParagraphSchema order anyOf item 0Type: integer root          paragraphs ParagraphSchema order anyOf item 1Type: null role Required root          paragraphs ParagraphSchema roleRole <p>Role of the paragraph, e.g., ['sectionheadings', 'pageheader', 'page_footer'])</p> Any of <ul><li> Option 1 </li><li> Option 2 </li></ul> root          paragraphs ParagraphSchema role anyOf item 0Type: string root          paragraphs ParagraphSchema role anyOf item 1Type: null tables Required root          tablesTablesType: array <p>List of detected tables</p> No Additional ItemsEach item of this array must be: root          tables TableStructureRecognizerSchemaTableStructureRecognizerSchemaType: object No Additional Properties box Required root          tables TableStructureRecognizerSchema boxBoxType: array of integer <p>Bounding box of the table in the format [x1, y1, x2, y2]</p> <p>Must contain a minimum of <code>4</code> items</p><p>Must contain a maximum of <code>4</code> items</p> No Additional ItemsEach item of this array must be: root          tables TableStructureRecognizerSchema box box itemsType: integer n_row Required root          tables TableStructureRecognizerSchema n_rowN RowType: integer <p>Number of rows in the table</p> n_col Required root          tables TableStructureRecognizerSchema n_colN ColType: integer <p>Number of columns in the table</p> rows Required root          tables TableStructureRecognizerSchema rowsRowsType: array <p>List of table lines representing rows</p> No Additional ItemsEach item of this array must be: root          tables TableStructureRecognizerSchema rows TableLineSchemaTableLineSchemaType: object No Additional Properties box Required root          tables TableStructureRecognizerSchema rows TableLineSchema boxBoxType: array of integer <p>Bounding box of the table line in the format [x1, y1, x2, y2]</p> <p>Must contain a minimum of <code>4</code> items</p><p>Must contain a maximum of <code>4</code> items</p> No Additional ItemsEach item of this array must be: root          tables TableStructureRecognizerSchema rows TableLineSchema box box itemsType: integer score Required root          tables TableStructureRecognizerSchema rows TableLineSchema scoreScoreType: number <p>Confidence score of the table line detection</p> cols Required root          tables TableStructureRecognizerSchema colsColsType: array <p>List of table lines representing columns</p> No Additional ItemsEach item of this array must be: root          tables TableStructureRecognizerSchema cols TableLineSchemaTableLineSchemaType: object Same definition as TableLineSchema spans Required root          tables TableStructureRecognizerSchema spansSpansType: array <p>List of table lines representing spans</p> No Additional ItemsEach item of this array must be: root          tables TableStructureRecognizerSchema spans TableLineSchemaTableLineSchemaType: object Same definition as TableLineSchema cells Required root          tables TableStructureRecognizerSchema cellsCellsType: array <p>List of table cells</p> No Additional ItemsEach item of this array must be: root          tables TableStructureRecognizerSchema cells TableCellSchemaTableCellSchemaType: object No Additional Properties col Required root          tables TableStructureRecognizerSchema cells TableCellSchema colColType: integer <p>Column index of the cell</p> row Required root          tables TableStructureRecognizerSchema cells TableCellSchema rowRowType: integer <p>Row index of the cell</p> col_span Required root          tables TableStructureRecognizerSchema cells TableCellSchema col_spanCol SpanType: integer <p>Number of columns spanned by the cell</p> row_span Required root          tables TableStructureRecognizerSchema cells TableCellSchema row_spanRow SpanType: integer <p>Number of rows spanned by the cell</p> box Required root          tables TableStructureRecognizerSchema cells TableCellSchema boxBoxType: array of integer <p>Bounding box of the cell in the format [x1, y1, x2, y2]</p> <p>Must contain a minimum of <code>4</code> items</p><p>Must contain a maximum of <code>4</code> items</p> No Additional ItemsEach item of this array must be: root          tables TableStructureRecognizerSchema cells TableCellSchema box box itemsType: integer contents Required root          tables TableStructureRecognizerSchema cells TableCellSchema contentsContents <p>Text content of the cell</p> Any of <ul><li> Option 1 </li><li> Option 2 </li></ul> root          tables TableStructureRecognizerSchema cells TableCellSchema contents anyOf item 0Type: string root          tables TableStructureRecognizerSchema cells TableCellSchema contents anyOf item 1Type: null order Required root          tables TableStructureRecognizerSchema orderOrderType: integer <p>Order of the table in the document</p> words Required root          wordsWordsType: array <p>List of recognized words</p> No Additional ItemsEach item of this array must be: root          words WordPredictionWordPredictionType: object No Additional Properties points Required root          words WordPrediction pointsPointsType: array of array <p>Bounding box of the word in the format [[x1, y1], [x2, y2], [x3, y3], [x4, y4]]</p> <p>Must contain a minimum of <code>4</code> items</p><p>Must contain a maximum of <code>4</code> items</p> No Additional ItemsEach item of this array must be: root          words WordPrediction points points itemsType: array of integer <p>Must contain a minimum of <code>2</code> items</p><p>Must contain a maximum of <code>2</code> items</p> No Additional ItemsEach item of this array must be: root          words WordPrediction points points items points items itemsType: integer content Required root          words WordPrediction contentContentType: string <p>Text content of the word</p> direction Required root          words WordPrediction directionDirectionType: string <p>Text direction, e.g., 'horizontal' or 'vertical'</p> rec_score Required root          words WordPrediction rec_scoreRec ScoreType: number <p>Confidence score of the word recognition</p> det_score Required root          words WordPrediction det_scoreDet ScoreType: number <p>Confidence score of the word detection</p> figures Required root          figuresFiguresType: array <p>List of detected figures</p> No Additional ItemsEach item of this array must be: root          figures FigureSchemaFigureSchemaType: object No Additional Properties box Required root          figures FigureSchema boxBoxType: array of integer <p>Bounding box of the figure in the format [x1, y1, x2, y2]</p> <p>Must contain a minimum of <code>4</code> items</p><p>Must contain a maximum of <code>4</code> items</p> No Additional ItemsEach item of this array must be: root          figures FigureSchema box box itemsType: integer order Required root          figures FigureSchema orderOrder <p>Order of the figure in the document</p> Any of <ul><li> Option 1 </li><li> Option 2 </li></ul> root          figures FigureSchema order anyOf item 0Type: integer root          figures FigureSchema order anyOf item 1Type: null paragraphs Required root          figures FigureSchema paragraphsParagraphsType: array <p>List of paragraphs associated with the figure</p> No Additional ItemsEach item of this array must be: root          figures FigureSchema paragraphs ParagraphSchemaParagraphSchemaType: object Same definition as ParagraphSchema direction Required root          figures FigureSchema directionDirection <p>Text direction, e.g., ['horizontal' or 'vertical']</p> Any of <ul><li> Option 1 </li><li> Option 2 </li></ul> root          figures FigureSchema direction anyOf item 0Type: string root          figures FigureSchema direction anyOf item 1Type: null <p>Generated using json-schema-for-humans on 2025-07-30 at 10:57:58 +0900</p>"},{"location":"","title":"Home","text":""},{"location":"#_1","title":"\ud83c\udf1f \u6982\u8981","text":"<p>YomiToku \u306f\u65e5\u672c\u8a9e\u306b\u7279\u5316\u3057\u305f AI \u6587\u7ae0\u753b\u50cf\u89e3\u6790\u30a8\u30f3\u30b8\u30f3(Document AI)\u3067\u3059\u3002\u753b\u50cf\u5185\u306e\u6587\u5b57\u306e\u5168\u6587 OCR \u304a\u3088\u3073\u30ec\u30a4\u30a2\u30a6\u30c8\u89e3\u6790\u6a5f\u80fd\u3092\u6709\u3057\u3066\u304a\u308a\u3001\u753b\u50cf\u5185\u306e\u6587\u5b57\u60c5\u5831\u3084\u56f3\u8868\u3092\u8a8d\u8b58\u3001\u62bd\u51fa\u3001\u5909\u63db\u3057\u307e\u3059\u3002</p> <ul> <li>\ud83e\udd16 \u65e5\u672c\u8a9e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u5b66\u7fd2\u3057\u305f 4 \u7a2e\u985e(\u6587\u5b57\u4f4d\u7f6e\u306e\u691c\u77e5\u3001\u6587\u5b57\u5217\u8a8d\u8b58\u3001\u30ec\u30a4\u30a2\u30a6\u30c8\u89e3\u6790\u3001\u8868\u306e\u69cb\u9020\u8a8d\u8b58)\u306e AI \u30e2\u30c7\u30eb\u3092\u642d\u8f09\u3057\u3066\u3044\u307e\u3059\u30024 \u7a2e\u985e\u306e\u30e2\u30c7\u30eb\u306f\u3059\u3079\u3066\u72ec\u81ea\u306b\u5b66\u7fd2\u3055\u308c\u305f\u30e2\u30c7\u30eb\u3067\u65e5\u672c\u8a9e\u6587\u66f8\u306b\u5bfe\u3057\u3066\u3001\u9ad8\u7cbe\u5ea6\u306b\u63a8\u8ad6\u53ef\u80fd\u3067\u3059\u3002</li> <li>\ud83c\uddef\ud83c\uddf5 \u5404\u30e2\u30c7\u30eb\u306f\u65e5\u672c\u8a9e\u306e\u6587\u66f8\u753b\u50cf\u306b\u7279\u5316\u3057\u3066\u5b66\u7fd2\u3055\u308c\u3066\u304a\u308a\u30017000 \u6587\u5b57\u3092\u8d85\u3048\u308b\u65e5\u672c\u8a9e\u6587\u5b57\u306e\u8a8d\u8b58\u3092\u30b5\u30dd\u30fc\u30c8\u3001\u624b\u66f8\u304d\u6587\u5b57\u3001\u7e26\u66f8\u304d\u306a\u3069\u65e5\u672c\u8a9e\u7279\u6709\u306e\u30ec\u30a4\u30a2\u30a6\u30c8\u69cb\u9020\u306e\u6587\u66f8\u753b\u50cf\u306e\u89e3\u6790\u3082\u53ef\u80fd\u3067\u3059\u3002\uff08\u65e5\u672c\u8a9e\u4ee5\u5916\u306b\u3082\u82f1\u8a9e\u306e\u6587\u66f8\u306b\u5bfe\u3057\u3066\u3082\u5bfe\u5fdc\u3057\u3066\u3044\u307e\u3059\uff09\u3002</li> <li>\ud83d\udcc8 \u30ec\u30a4\u30a2\u30a6\u30c8\u89e3\u6790\u3001\u8868\u306e\u69cb\u9020\u89e3\u6790, \u8aad\u307f\u9806\u63a8\u5b9a\u6a5f\u80fd\u306b\u3088\u308a\u3001\u6587\u66f8\u753b\u50cf\u306e\u30ec\u30a4\u30a2\u30a6\u30c8\u306e\u610f\u5473\u7684\u69cb\u9020\u3092\u58ca\u3055\u305a\u306b\u60c5\u5831\u3092\u62bd\u51fa\u3059\u308b\u3053\u3068\u304c\u53ef\u80fd\u3067\u3059\u3002</li> <li>\ud83d\udcc4 \u591a\u69d8\u306a\u51fa\u529b\u5f62\u5f0f\u3092\u30b5\u30dd\u30fc\u30c8\u3057\u3066\u3044\u307e\u3059\u3002html \u3084\u30de\u30fc\u30af\u30c0\u30a6\u30f3\u3001json\u3001csv \u306e\u3044\u305a\u308c\u304b\u306e\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u306b\u5909\u63db\u53ef\u80fd\u3067\u3059\u3002\u307e\u305f\u3001\u6587\u66f8\u5185\u306b\u542b\u307e\u308c\u308b\u56f3\u8868\u3001\u753b\u50cf\u306e\u62bd\u51fa\u306e\u51fa\u529b\u3082\u53ef\u80fd\u3067\u3059\u3002\u6587\u66f8\u753b\u50cf\u3092\u5168\u6587\u691c\u7d22\u53ef\u80fd\u306a\u30b5\u30fc\u30c1\u30e3\u30d6\u30ebPDF\u306b\u5909\u63db\u3059\u308b\u51e6\u7406\u3082\u30b5\u30dd\u30fc\u30c8\u3057\u3066\u3044\u307e\u3059\u3002</li> <li>\u26a1 GPU \u74b0\u5883\u3067\u9ad8\u901f\u306b\u52d5\u4f5c\u3057\u3001\u52b9\u7387\u7684\u306b\u6587\u66f8\u306e\u6587\u5b57\u8d77\u3053\u3057\u89e3\u6790\u304c\u53ef\u80fd\u3067\u3059\u3002\u307e\u305f\u3001VRAM \u3082 8GB \u4ee5\u5185\u3067\u52d5\u4f5c\u3057\u3001\u30cf\u30a4\u30a8\u30f3\u30c9\u306a GPU \u3092\u7528\u610f\u3059\u308b\u5fc5\u8981\u306f\u3042\u308a\u307e\u305b\u3093\u3002</li> </ul>"},{"location":"#faq","title":"\ud83d\ude4b FAQ","text":""},{"location":"#q","title":"Q. \u30a4\u30f3\u30bf\u30fc\u30cd\u30c3\u30c8\u306b\u63a5\u7d9a\u3067\u304d\u306a\u3044\u74b0\u5883\u3067\u306e\u52d5\u4f5c\u306f\u53ef\u80fd\u3067\u3059\u304b\uff1f","text":"<p>A. \u53ef\u80fd\u3067\u3059\u3002Yomitoku \u306f\u521d\u56de\u5b9f\u884c\u6642\u306b HuggingFaceHub \u306b\u30a2\u30af\u30bb\u30b9\u3057\u3001\u81ea\u52d5\u3067\u30e2\u30c7\u30eb\u30d5\u30a1\u30a4\u30eb\u306e\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3092\u884c\u3044\u307e\u3059\u304c\u3001\u3053\u306e\u969b\u306b\u30a4\u30f3\u30bf\u30fc\u30cd\u30c3\u30c8\u306b\u63a5\u7d9a\u3057\u307e\u3059\u3002\u3057\u304b\u3057\u3001\u4e8b\u524d\u306b\u624b\u52d5\u3067\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3059\u308b\u3053\u3068\u3067\u30a4\u30f3\u30bf\u30fc\u30cd\u30c3\u30c8\u3078\u63a5\u7d9a\u3067\u304d\u306a\u3044\u74b0\u5883\u3067\u3082\u52d5\u4f5c\u53ef\u80fd\u3067\u3059\u3002\u8a73\u3057\u304f\u306fModule Usase\u306e\u300c\u30a4\u30f3\u30bf\u30fc\u30cd\u30c3\u30c8\u306b\u63a5\u7d9a\u3067\u304d\u306a\u3044\u74b0\u5883\u3067\u306e\u5229\u7528\u300d\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044\u3002</p>"},{"location":"#q_1","title":"Q. \u5546\u7528\u5229\u7528\u306f\u53ef\u80fd\u3067\u3059\u304b\uff1f","text":"<p>A. \u672c\u30d1\u30c3\u30b1\u30fc\u30b8\u306f CC BY-NC 4.0 \u306b\u5f93\u3044\u307e\u3059\u3002\u500b\u4eba\u306e\u5229\u7528\u3084\u7814\u7a76\u5229\u7528\u306b\u95a2\u3057\u3066\u306f\u7121\u511f\u3067\u3054\u5229\u7528\u3044\u305f\u3060\u3051\u307e\u3059\u3002\u5546\u7528\u5229\u7528\u306b\u95a2\u3057\u3066\u306f\u3001\u5225\u9014\u3001\u6709\u511f\u306e\u5546\u7528\u30e9\u30a4\u30bb\u30f3\u30b9\u3092\u767a\u884c\u3057\u307e\u3059\u306e\u3067\u3001\u958b\u767a\u8005\u307e\u3067\u554f\u3044\u5408\u308f\u305b\u304f\u3060\u3055\u3044\u3002</p>"},{"location":"installation/","title":"Installation","text":"<p>\u672c\u30d1\u30c3\u30b1\u30fc\u30b8\u306f Python3.10+, Pytorch \u304c\u5b9f\u884c\u306b\u5fc5\u8981\u3067\u3059\u3002Pytorch \u306f\u3054\u81ea\u8eab\u306e\u74b0\u5883\u306b\u5408\u308f\u305b\u3066\u3001\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u304c\u5fc5\u8981\u3067\u3059\u3002\u8a08\u7b97\u6a5f\u306f GPU(&gt; VRAM 8G)\u3092\u63a8\u5968\u3057\u3066\u3044\u307e\u3059\u3002CPU \u3067\u3082\u52d5\u4f5c\u3057\u307e\u3059\u304c\u3001\u73fe\u5728\u3001CPU \u5411\u3051\u306b\u51e6\u7406\u304c\u6700\u9069\u5316\u3055\u308c\u3066\u304a\u3089\u305a\u3001\u5b9f\u884c\u306b\u6642\u9593\u304c\u304b\u304b\u308a\u307e\u3059\u306e\u3067\u3054\u6ce8\u610f\u304f\u3060\u3055\u3044\u3002</p>"},{"location":"installation/#pypi","title":"PYPI \u304b\u3089\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb","text":"<pre><code>pip install yomitoku\n</code></pre>"},{"location":"installation/#uv","title":"uv \u3067\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb","text":"<p>\u672c\u30ea\u30dd\u30b8\u30c8\u30ea\u306f\u30d1\u30c3\u30b1\u30fc\u30b8\u7ba1\u7406\u30c4\u30fc\u30eb\u306b uv \u3092\u4f7f\u7528\u3057\u3066\u3044\u307e\u3059\u3002uv \u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u5f8c\u3001\u30ea\u30dd\u30b8\u30c8\u30ea\u3092\u30af\u30ed\u30fc\u30f3\u3057\u3001\u4ee5\u4e0b\u306e\u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c\u3057\u3066\u304f\u3060\u3055\u3044</p> <pre><code>uv sync\n</code></pre> <p>onnxruntime\u306e\u5b9f\u884c\u306bGPU\u3092\u4f7f\u7528\u3059\u308b\u5834\u5408 <pre><code>uv sync --extra gpu\n</code></pre></p> <p>uv\u3092\u5229\u7528\u3059\u308b\u5834\u5408\u3001<code>pyproject.toml</code>\u306e\u4ee5\u4e0b\u306e\u90e8\u5206\u3092\u3054\u81ea\u8eab\u306ecuda\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u306b\u5408\u308f\u305b\u3066\u4fee\u6b63\u3059\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002\u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u306fCUDA12.4\u306b\u5bfe\u5fdc\u3057\u305fpytorch\u304c\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3055\u308c\u307e\u3059\u3002</p> <pre><code>[[tool.uv.index]]\nname = \"pytorch-cuda124\"\nurl = \"https://download.pytorch.org/whl/cu124\"\nexplicit = true\n</code></pre>"},{"location":"installation/#docker","title":"Docker \u74b0\u5883\u3067\u306e\u5b9f\u884c","text":"<p>\u30ea\u30dd\u30b8\u30c8\u30ea\u306e\u76f4\u4e0b\u306b dockerfile \u3092\u914d\u7f6e\u3057\u3066\u3044\u307e\u3059\u306e\u3067\u3001\u305d\u3061\u3089\u3082\u6d3b\u7528\u3044\u305f\u3060\u3051\u307e\u3059\u3002</p> <pre><code>docker build -t yomitoku .\n</code></pre> GPUCPU <pre><code>docker run -it --gpus all -v $(pwd):/workspace --name yomitoku yomitoku /bin/bash\n</code></pre> <pre><code>docker run -it -v $(pwd):/workspace --name yomitoku yomitoku /bin/bash\n</code></pre>"},{"location":"layout_analyzer_schema/","title":"Layout Analyzer","text":"LayoutAnalyzerSchema LayoutAnalyzerSchemaType: object No Additional Properties paragraphs Required root          paragraphsParagraphsType: array <p>List of detected paragraphs</p> No Additional ItemsEach item of this array must be: root          paragraphs ElementElementType: object No Additional Properties box Required root          paragraphs Element boxBoxType: array of integer <p>Bounding box of the layout element in the format [x1, y1, x2, y2]</p> <p>Must contain a minimum of <code>4</code> items</p><p>Must contain a maximum of <code>4</code> items</p> No Additional ItemsEach item of this array must be: root          paragraphs Element box box itemsType: integer score Required root          paragraphs Element scoreScoreType: number <p>Confidence score of the layout element detection</p> role Required root          paragraphs Element roleRole <p>Role of the element, e.g., ['sectionheadings', 'pageheader', 'pagefooter', 'listitem', 'caption', 'inlineformula', 'displayformula', 'index']</p> Any of <ul><li> Option 1 </li><li> Option 2 </li></ul> root          paragraphs Element role anyOf item 0Type: string root          paragraphs Element role anyOf item 1Type: null tables Required root          tablesTablesType: array <p>List of detected tables</p> No Additional ItemsEach item of this array must be: root          tables TableStructureRecognizerSchemaTableStructureRecognizerSchemaType: object No Additional Properties box Required root          tables TableStructureRecognizerSchema boxBoxType: array of integer <p>Bounding box of the table in the format [x1, y1, x2, y2]</p> <p>Must contain a minimum of <code>4</code> items</p><p>Must contain a maximum of <code>4</code> items</p> No Additional ItemsEach item of this array must be: root          tables TableStructureRecognizerSchema box box itemsType: integer n_row Required root          tables TableStructureRecognizerSchema n_rowN RowType: integer <p>Number of rows in the table</p> n_col Required root          tables TableStructureRecognizerSchema n_colN ColType: integer <p>Number of columns in the table</p> rows Required root          tables TableStructureRecognizerSchema rowsRowsType: array <p>List of table lines representing rows</p> No Additional ItemsEach item of this array must be: root          tables TableStructureRecognizerSchema rows TableLineSchemaTableLineSchemaType: object No Additional Properties box Required root          tables TableStructureRecognizerSchema rows TableLineSchema boxBoxType: array of integer <p>Bounding box of the table line in the format [x1, y1, x2, y2]</p> <p>Must contain a minimum of <code>4</code> items</p><p>Must contain a maximum of <code>4</code> items</p> No Additional ItemsEach item of this array must be: root          tables TableStructureRecognizerSchema rows TableLineSchema box box itemsType: integer score Required root          tables TableStructureRecognizerSchema rows TableLineSchema scoreScoreType: number <p>Confidence score of the table line detection</p> cols Required root          tables TableStructureRecognizerSchema colsColsType: array <p>List of table lines representing columns</p> No Additional ItemsEach item of this array must be: root          tables TableStructureRecognizerSchema cols TableLineSchemaTableLineSchemaType: object Same definition as TableLineSchema spans Required root          tables TableStructureRecognizerSchema spansSpansType: array <p>List of table lines representing spans</p> No Additional ItemsEach item of this array must be: root          tables TableStructureRecognizerSchema spans TableLineSchemaTableLineSchemaType: object Same definition as TableLineSchema cells Required root          tables TableStructureRecognizerSchema cellsCellsType: array <p>List of table cells</p> No Additional ItemsEach item of this array must be: root          tables TableStructureRecognizerSchema cells TableCellSchemaTableCellSchemaType: object No Additional Properties col Required root          tables TableStructureRecognizerSchema cells TableCellSchema colColType: integer <p>Column index of the cell</p> row Required root          tables TableStructureRecognizerSchema cells TableCellSchema rowRowType: integer <p>Row index of the cell</p> col_span Required root          tables TableStructureRecognizerSchema cells TableCellSchema col_spanCol SpanType: integer <p>Number of columns spanned by the cell</p> row_span Required root          tables TableStructureRecognizerSchema cells TableCellSchema row_spanRow SpanType: integer <p>Number of rows spanned by the cell</p> box Required root          tables TableStructureRecognizerSchema cells TableCellSchema boxBoxType: array of integer <p>Bounding box of the cell in the format [x1, y1, x2, y2]</p> <p>Must contain a minimum of <code>4</code> items</p><p>Must contain a maximum of <code>4</code> items</p> No Additional ItemsEach item of this array must be: root          tables TableStructureRecognizerSchema cells TableCellSchema box box itemsType: integer contents Required root          tables TableStructureRecognizerSchema cells TableCellSchema contentsContents <p>Text content of the cell</p> Any of <ul><li> Option 1 </li><li> Option 2 </li></ul> root          tables TableStructureRecognizerSchema cells TableCellSchema contents anyOf item 0Type: string root          tables TableStructureRecognizerSchema cells TableCellSchema contents anyOf item 1Type: null order Required root          tables TableStructureRecognizerSchema orderOrderType: integer <p>Order of the table in the document</p> figures Required root          figuresFiguresType: array <p>List of detected figures</p> No Additional ItemsEach item of this array must be: root          figures ElementElementType: object Same definition as Element <p>Generated using json-schema-for-humans on 2025-07-30 at 10:57:58 +0900</p>"},{"location":"mcp/","title":"MCP","text":"<p>\u3053\u3053\u3067\u306fYomitoku\u306eMCP\u30b5\u30fc\u30d0\u30fc\u3092Claude Desktop\u306b\u9023\u643a\u3057\u3066\u5229\u7528\u3059\u308b\u65b9\u6cd5\u3092\u8aac\u660e\u3057\u307e\u3059\u3002</p>"},{"location":"mcp/#yomitoku","title":"Yomitoku\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb","text":"<p>\u307e\u305a\u306f Installation\u306e\u300cuv\u3067\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u300d\u306b\u5f93\u3063\u3066Yomitoku\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u3066\u304f\u3060\u3055\u3044\u3002</p> <p>\u305f\u3060\u3057\u3001<code>mcp</code>\u3092\u4f9d\u5b58\u95a2\u4fc2\u306b\u8ffd\u52a0\u3059\u308b\u305f\u3081\u306b\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u6642\u306b\u306f\u4e0b\u8a18\u306e\u3088\u3046\u306b<code>--extra</code>\u306b<code>mcp</code>\u3092\u52a0\u3048\u307e\u3059\u3002</p> <pre><code>uv sync --extra mcp\n</code></pre>"},{"location":"mcp/#claude-desktop","title":"Claude Desktop\u306e\u8a2d\u5b9a","text":"<p>\u6b21\u306bClaude Desktop\u306e\u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb\u306e<code>mcpServers</code>\u306b\u4ee5\u4e0b\u3088\u3046\u306b\u8a2d\u5b9a\u3092\u8ffd\u52a0\u3057\u307e\u3059\u3002(\u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb\u306e\u958b\u304d\u65b9\u306f\u3053\u3061\u3089\u3092\u53c2\u7167\u3057\u3066\u304f\u3060\u3055\u3044)</p> <pre><code>{\n  \"mcpServers\": {\n    \"yomitoku\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"(Yomitoku\u3092Clone\u3057\u305f\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306e\u7d76\u5bfe\u30d1\u30b9)\",\n        \"run\",\n        \"yomitoku_mcp\"\n      ],\n      \"env\": {\n        \"RESOURCE_DIR\": \"(OCR\u5bfe\u8c61\u306e\u30d5\u30a1\u30a4\u30eb\u304c\u3042\u308b\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306e\u7d76\u5bfe\u30d1\u30b9)\"\n      }\n    }\n  }\n}\n</code></pre> <p>\u4f8b\u3048\u3070\u3001<code>/Users/your-username/workspace</code>\u3067<code>git clone https://github.com/kotaro-kinoshita/yomitoku.git</code>\u3092\u5b9f\u884c\u3057\u305f\u5834\u5408\u306f\u3001<code>(Yomitoku\u3092Clone\u3057\u305f\u30c7\u30a3\u30ec\u30af\u30c8\u30ea)</code>\u306f<code>/Users/your-username/workspace/yomitoku</code>\u3068\u306a\u308a\u3001<code>yomitoku/demo</code>\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306e<code>sample.pdf</code>\u3092\u7528\u3044\u308b\u5834\u5408\u306f<code>(OCR\u5bfe\u8c61\u306e\u30d5\u30a1\u30a4\u30eb\u304c\u3042\u308b\u30c7\u30a3\u30ec\u30af\u30c8\u30ea)</code>\u3092<code>/Users/your-username/workspace/yomitoku/demo</code>\u3068\u6307\u5b9a\u3057\u307e\u3059\u3002</p>"},{"location":"mcp/#claude-desktop_1","title":"Claude Desktop\u3067\u306e\u5229\u7528","text":"<p>\u203b \u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb\u306e\u5909\u66f4\u3092\u53cd\u6620\u3059\u308b\u306b\u306fClaude Desktop\u3092\u518d\u8d77\u52d5\u3057\u3066\u304f\u3060\u3055\u3044\u3002</p> <p>\u4f8b\u3048\u3070<code>yomitoku/demo/sample.pdf</code>\u3092\u30b5\u30f3\u30d7\u30eb\u3068\u3057\u3066\u7528\u3044\u308b\u5834\u5408\u3001\u4e0b\u8a18\u306e\u3088\u3046\u306b\u6307\u793a\u3057\u3066\u304f\u3060\u3055\u3044\u3002</p> <pre><code>sample.pdf\u3092OCR\u3067\u89e3\u6790\u3057\u3066\u8981\u7d04\u3057\u3066\u304f\u3060\u3055\u3044\u3002\n</code></pre>"},{"location":"mcp/#sse","title":"SSE\u30b5\u30fc\u30d0\u30fc\u306e\u8d77\u52d5","text":"<p>\u74b0\u5883\u5909\u6570\u306e<code>RESOURCE_DIR</code>\u306bOCR\u306e\u5bfe\u8c61\u753b\u50cf\u304c\u542b\u307e\u308c\u305f\u30d5\u30a9\u30eb\u30c0\u306e\u30d1\u30b9\u3092\u8a2d\u5b9a\u3057\u3066\u304f\u3060\u3055\u3044\u3002 <pre><code>export RESOURCE_DIR=\"path of dataset\"\n</code></pre></p> <p>\u4ee5\u4e0b\u306e\u30b3\u30de\u30f3\u30c9\u3067SSE\u30b5\u30fc\u30d0\u30fc\u3092\u8d77\u52d5\u3057\u307e\u3059\u3002 <pre><code>uv run yomitoku_mcp -t sse\n</code></pre></p> <p><code>http://127.0.0.1:8000/sse</code>\u304cSSE\u30b5\u30fc\u30d0\u30fc\u306e\u30a8\u30f3\u30c9\u30dd\u30a4\u30f3\u30c8\u306b\u306a\u308a\u307e\u3059\u3002</p>"},{"location":"module/","title":"\u30e2\u30b8\u30e5\u30fc\u30eb\u3068\u3057\u3066\u306e\u30b3\u30fc\u30c9\u5185\u3067\u306e\u5229\u7528","text":""},{"location":"module/#document-analyzer","title":"Document Analyzer \u306e\u5229\u7528","text":"<p>Document Analyzer \u306f OCR \u304a\u3088\u3073\u30ec\u30a4\u30a2\u30a6\u30c8\u89e3\u6790\u3092\u5b9f\u884c\u3057\u3001\u305d\u308c\u3089\u306e\u7d50\u679c\u3092\u7d71\u5408\u3057\u305f\u89e3\u6790\u7d50\u679c\u3092\u8fd4\u5374\u3057\u307e\u3059\u3002\u6bb5\u843d\u3001\u8868\u306e\u69cb\u9020\u89e3\u6790\u3001\u62bd\u51fa\u3001\u56f3\u8868\u306e\u691c\u77e5\u306a\u3069\u69d8\u3005\u306a\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u306b\u3054\u5229\u7528\u3044\u305f\u3060\u3051\u307e\u3059\u3002</p> demo/simple_document_analysis.py <pre><code>import cv2\n\n\n\nfrom yomitoku import DocumentAnalyzer\n\nfrom yomitoku.data.functions import load_pdf\n\n\n\nif __name__ == \"__main__\":\n\n    PATH_IMGE = \"demo/sample.pdf\"\n\n    analyzer = DocumentAnalyzer(visualize=True, device=\"cuda\")\n\n    # PDF\u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u307f\u8fbc\u307f\n\n    imgs = load_pdf(PATH_IMGE)\n\n    for i, img in enumerate(imgs):\n\n        results, ocr_vis, layout_vis = analyzer(img)\n\n        # HTML\u5f62\u5f0f\u3067\u89e3\u6790\u7d50\u679c\u3092\u30a8\u30af\u30b9\u30dd\u30fc\u30c8\n\n        results.to_html(f\"output_{i}.html\", img=img)\n\n        # \u53ef\u8996\u5316\u753b\u50cf\u3092\u4fdd\u5b58\n\n        cv2.imwrite(f\"output_ocr_{i}.jpg\", ocr_vis)\n\n        cv2.imwrite(f\"output_layout_{i}.jpg\", layout_vis)\n</code></pre> <ul> <li><code>visualize</code> \u3092 True \u306b\u3059\u308b\u3068\u5404\u51e6\u7406\u7d50\u679c\u3092\u53ef\u8996\u5316\u3057\u305f\u7d50\u679c\u3092\u7b2c\uff12\u3001\u7b2c 3 \u623b\u308a\u5024\u306b OCR\u3001\u30ec\u30a2\u30a6\u30c8\u89e3\u6790\u306e\u51e6\u7406\u7d50\u679c\u3092\u305d\u308c\u305e\u308c\u683c\u7d0d\u3057\u3001\u8fd4\u5374\u3057\u307e\u3059\u3002False \u306b\u3057\u305f\u5834\u5408\u306f None \u3092\u8fd4\u5374\u3057\u307e\u3059\u3002\u63cf\u753b\u51e6\u7406\u306e\u305f\u3081\u306e\u8a08\u7b97\u304c\u5897\u52a0\u3057\u307e\u3059\u306e\u3067\u3001\u30c7\u30d0\u30c3\u30af\u7528\u9014\u3067\u306a\u3044\u5834\u5408\u306f\u3001False \u3092\u63a8\u5968\u3057\u307e\u3059\u3002</li> <li><code>device</code> \u306b\u306f\u51e6\u7406\u306b\u7528\u3044\u308b\u8a08\u7b97\u6a5f\u3092\u6307\u5b9a\u3057\u307e\u3059\u3002Default \u306f\"cuda\". GPU \u304c\u5229\u7528\u3067\u304d\u306a\u3044\u5834\u5408\u306f\u3001\u81ea\u52d5\u3067 CPU \u30e2\u30fc\u30c9\u306b\u5207\u308a\u66ff\u3048\u3066\u51e6\u7406\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002</li> <li><code>configs</code>\u3092\u6d3b\u7528\u3059\u308b\u3068\u3001\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u306e\u51e6\u7406\u306e\u3088\u308a\u8a73\u7d30\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u8a2d\u5b9a\u3067\u304d\u307e\u3059\u3002</li> </ul> <p><code>DocumentAnalyzer</code> \u306e\u51e6\u7406\u7d50\u679c\u306e\u30a8\u30af\u30b9\u30dd\u30fc\u30c8\u306f\u4ee5\u4e0b\u306b\u5bfe\u5fdc\u3057\u3066\u3044\u307e\u3059\u3002</p> <ul> <li><code>to_json()</code>: JSON \u5f62\u5f0f(*.json)</li> <li><code>to_html()</code>: HTML \u5f62\u5f0f(*.html)</li> <li><code>to_csv()</code>: \u30ab\u30f3\u30de\u533a\u5207\u308a CSV \u5f62\u5f0f(*.csv)</li> <li><code>to_markdown()</code>: \u30de\u30fc\u30af\u30c0\u30a6\u30f3\u5f62\u5f0f(*.md)</li> </ul>"},{"location":"module/#ai-ocr","title":"AI-OCR \u306e\u307f\u306e\u5229\u7528","text":"<p>AI-OCR \u3067\u306f\u3001\u30c6\u30ad\u30b9\u30c8\u691c\u77e5\u3068\u691c\u77e5\u3057\u305f\u30c6\u30ad\u30b9\u30c8\u306b\u5bfe\u3057\u3066\u3001\u8a8d\u8b58\u51e6\u7406\u3092\u5b9f\u884c\u3057\u3001\u753b\u50cf\u5185\u306e\u6587\u5b57\u306e\u4f4d\u7f6e\u3068\u8aad\u307f\u53d6\u308a\u7d50\u679c\u3092\u8fd4\u5374\u3057\u307e\u3059\u3002</p> demo/simple_ocr.py <pre><code>import cv2\n\n\n\nfrom yomitoku import OCR\n\nfrom yomitoku.data.functions import load_pdf\n\n\n\nif __name__ == \"__main__\":\n\n    ocr = OCR(visualize=True, device=\"cuda\")\n\n    # PDF\u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u307f\u8fbc\u307f\n\n    imgs = load_pdf(\"demo/sample.pdf\")\n\n    import time\n\n\n\n    start = time.time()\n\n    for i, img in enumerate(imgs):\n\n        results, ocr_vis = ocr(img)\n\n\n\n        # JSON\u5f62\u5f0f\u3067\u89e3\u6790\u7d50\u679c\u3092\u30a8\u30af\u30b9\u30dd\u30fc\u30c8\n\n        results.to_json(f\"output_{i}.json\")\n\n        cv2.imwrite(f\"output_ocr_{i}.jpg\", ocr_vis)\n</code></pre> <ul> <li><code>visualize</code> \u3092 True \u306b\u3059\u308b\u3068\u5404\u51e6\u7406\u7d50\u679c\u3092\u53ef\u8996\u5316\u3057\u305f\u7d50\u679c\u3092\u7b2c\uff12\u3001\u7b2c 3 \u623b\u308a\u5024\u306b OCR\u3001\u30ec\u30a2\u30a6\u30c8\u89e3\u6790\u306e\u51e6\u7406\u7d50\u679c\u3092\u305d\u308c\u305e\u308c\u683c\u7d0d\u3057\u3001\u8fd4\u5374\u3057\u307e\u3059\u3002False \u306b\u3057\u305f\u5834\u5408\u306f None \u3092\u8fd4\u5374\u3057\u307e\u3059\u3002\u63cf\u753b\u51e6\u7406\u306e\u305f\u3081\u306e\u8a08\u7b97\u304c\u5897\u52a0\u3057\u307e\u3059\u306e\u3067\u3001\u30c7\u30d0\u30c3\u30af\u7528\u9014\u3067\u306a\u3044\u5834\u5408\u306f\u3001False \u3092\u63a8\u5968\u3057\u307e\u3059\u3002</li> <li><code>device</code> \u306b\u306f\u51e6\u7406\u306b\u7528\u3044\u308b\u8a08\u7b97\u6a5f\u3092\u6307\u5b9a\u3057\u307e\u3059\u3002Default \u306f\"cuda\". GPU \u304c\u5229\u7528\u3067\u304d\u306a\u3044\u5834\u5408\u306f\u3001\u81ea\u52d5\u3067 CPU \u30e2\u30fc\u30c9\u306b\u5207\u308a\u66ff\u3048\u3066\u51e6\u7406\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002</li> <li><code>configs</code>\u3092\u6d3b\u7528\u3059\u308b\u3068\u3001\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u306e\u51e6\u7406\u306e\u3088\u308a\u8a73\u7d30\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u8a2d\u5b9a\u3067\u304d\u307e\u3059\u3002</li> </ul> <p><code>OCR</code>\u306e\u51e6\u7406\u7d50\u679c\u306e\u30a8\u30af\u30b9\u30dd\u30fc\u30c8\u306f JSON \u7cfb\u5f62\u5f0f(<code>to_json()</code>)\u306e\u307f\u30b5\u30dd\u30fc\u30c8\u3057\u3066\u3044\u307e\u3059\u3002</p>"},{"location":"module/#layout-analyzer","title":"Layout Analyzer \u306e\u307f\u306e\u5229\u7528","text":"<p>LayoutAnalyzer \u3067\u306f\u3001\u30c6\u30ad\u30b9\u30c8\u691c\u77e5\u3068\u691c\u77e5\u3057\u305f\u30c6\u30ad\u30b9\u30c8\u306b\u5bfe\u3057\u3066\u3001\u6bb5\u843d\u3001\u56f3\u8868\u306e\u691c\u77e5\u304a\u3088\u3073\u8868\u306e\u69cb\u9020\u89e3\u6790\u51e6\u7406 AI \u3092\u5b9f\u884c\u3057\u3001\u6587\u66f8\u5185\u306e\u30ec\u30a4\u30a2\u30a6\u30c8\u69cb\u9020\u3092\u89e3\u6790\u3057\u307e\u3059\u3002</p> demo/simple_layout.py <pre><code>import cv2\n\n\n\nfrom yomitoku import LayoutAnalyzer\n\nfrom yomitoku.data.functions import load_pdf\n\n\n\nif __name__ == \"__main__\":\n\n    analyzer = LayoutAnalyzer(visualize=True, device=\"cuda\")\n\n    # PDF\u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u307f\u8fbc\u307f\n\n    imgs = load_pdf(\"demo/sample.pdf\")\n\n    for i, img in enumerate(imgs):\n\n        results, layout_vis = analyzer(img)\n\n\n\n        # JSON\u5f62\u5f0f\u3067\u89e3\u6790\u7d50\u679c\u3092\u30a8\u30af\u30b9\u30dd\u30fc\u30c8\n\n        results.to_json(f\"output_{i}.json\")\n\n        cv2.imwrite(f\"output_layout_{i}.jpg\", layout_vis)\n</code></pre> <ul> <li><code>visualize</code> \u3092 True \u306b\u3059\u308b\u3068\u5404\u51e6\u7406\u7d50\u679c\u3092\u53ef\u8996\u5316\u3057\u305f\u7d50\u679c\u3092\u7b2c\uff12\u3001\u7b2c 3 \u623b\u308a\u5024\u306b OCR\u3001\u30ec\u30a2\u30a6\u30c8\u89e3\u6790\u306e\u51e6\u7406\u7d50\u679c\u3092\u305d\u308c\u305e\u308c\u683c\u7d0d\u3057\u3001\u8fd4\u5374\u3057\u307e\u3059\u3002False \u306b\u3057\u305f\u5834\u5408\u306f None \u3092\u8fd4\u5374\u3057\u307e\u3059\u3002\u63cf\u753b\u51e6\u7406\u306e\u305f\u3081\u306e\u8a08\u7b97\u304c\u5897\u52a0\u3057\u307e\u3059\u306e\u3067\u3001\u30c7\u30d0\u30c3\u30af\u7528\u9014\u3067\u306a\u3044\u5834\u5408\u306f\u3001False \u3092\u63a8\u5968\u3057\u307e\u3059\u3002</li> <li><code>device</code> \u306b\u306f\u51e6\u7406\u306b\u7528\u3044\u308b\u8a08\u7b97\u6a5f\u3092\u6307\u5b9a\u3057\u307e\u3059\u3002Default \u306f\"cuda\". GPU \u304c\u5229\u7528\u3067\u304d\u306a\u3044\u5834\u5408\u306f\u3001\u81ea\u52d5\u3067 CPU \u30e2\u30fc\u30c9\u306b\u5207\u308a\u66ff\u3048\u3066\u51e6\u7406\u3092\u5b9f\u884c\u3057\u307e\u3059\u3002</li> <li><code>configs</code>\u3092\u6d3b\u7528\u3059\u308b\u3068\u3001\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u306e\u51e6\u7406\u306e\u3088\u308a\u8a73\u7d30\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u8a2d\u5b9a\u3067\u304d\u307e\u3059\u3002</li> </ul> <p><code>LayoutAnalyzer</code>\u306e\u51e6\u7406\u7d50\u679c\u306e\u30a8\u30af\u30b9\u30dd\u30fc\u30c8\u306f JSON \u7cfb\u5f62\u5f0f(<code>to_json()</code>)\u306e\u307f\u30b5\u30dd\u30fc\u30c8\u3057\u3066\u3044\u307e\u3059\u3002</p>"},{"location":"module/#_2","title":"\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u306e\u8a73\u7d30\u8a2d\u5b9a","text":"<p>Config \u3092\u4e0e\u3048\u308b\u3053\u3068\u3067\u3001\u3088\u308a\u7d30\u304b\u3044\u632f\u308b\u821e\u3044\u3092\u8abf\u6574\u3067\u304d\u307e\u3059\u3002\u30e2\u30b8\u30e5\u30fc\u30eb\u306b\u5bfe\u3057\u3066\u3001\u4ee5\u4e0b\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u8a2d\u5b9a\u53ef\u80fd\u3067\u3059\u3002</p> <ul> <li>model_name: \u30e2\u30c7\u30eb\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u3092\u4e0e\u3048\u307e\u3059</li> <li>path_cfg: \u30cf\u30a4\u30d1\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u4e0e\u3048\u305f config \u306e\u30d1\u30b9\u3092\u5165\u529b\u3057\u307e\u3059\u3002</li> <li>device: \u63a8\u8ad6\u306b\u4f7f\u7528\u3059\u308b\u30c7\u30d0\u30a4\u30b9\u3092\u4e0e\u3048\u307e\u3059\u3002(cuda | cpu | mps)</li> <li>visualize: \u53ef\u8996\u5316\u51e6\u7406\u306e\u5b9f\u65bd\u306e\u6709\u7121\u3092\u6307\u5b9a\u3057\u307e\u3059\u3002(boolean)</li> <li>from_pretrained: Pretrained \u30e2\u30c7\u30eb\u3092\u4f7f\u7528\u3059\u308b\u304b\u3069\u3046\u304b\u3092\u6307\u5b9a\u3057\u307e\u3059(boolean)</li> <li>infer_onnx: torch \u306e\u4ee3\u308f\u308a\u306b onnxruntime \u3092\u4f7f\u7528\u3057\u3066\u3001\u63a8\u8ad6\u3059\u308b\u304b\u3069\u3046\u304b\u3092\u6307\u5b9a\u3057\u307e\u3059(boolean)</li> </ul> <p>\u30b5\u30dd\u30fc\u30c8\u3055\u308c\u308b\u30e2\u30c7\u30eb\u306e\u7a2e\u985e(model_name)</p> <ul> <li>TextRecognizer: \"parseq\", \"parseq-small\"</li> <li>TextDetector: \"dbnet\"</li> <li>LayoutParser: \"rtdetrv2\"</li> <li>TableStructureRecognizer: \"rtdetrv2\"</li> </ul>"},{"location":"module/#config","title":"Config \u306e\u8a18\u8ff0\u65b9\u6cd5","text":"<p>config \u306f\u8f9e\u66f8\u5f62\u5f0f\u3067\u4e0e\u3048\u307e\u3059\u3002config \u3092\u4e0e\u3048\u308b\u3053\u3068\u3067\u30e2\u30b8\u30e5\u30fc\u30eb\u3054\u3068\u306b\u7570\u306a\u308b\u8a08\u7b97\u6a5f\u3067\u51e6\u7406\u3092\u5b9f\u884c\u3057\u305f\u308a\u3001\u8a73\u7d30\u306e\u30d1\u30e9\u30fc\u30e1\u30bf\u306e\u8a2d\u5b9a\u304c\u53ef\u80fd\u3067\u3059\u3002\u4f8b\u3048\u3070\u4ee5\u4e0b\u306e\u3088\u3046\u306a config \u3092\u4e0e\u3048\u308b\u3068\u3001OCR \u51e6\u7406\u306f GPU \u3067\u5b9f\u884c\u3057\u3001\u30ec\u30a4\u30a2\u30a6\u30c8\u89e3\u6790\u6a5f\u80fd\u306f CPU \u3067\u5b9f\u884c\u3057\u307e\u3059\u3002</p> <pre><code>from yomitoku import DocumentAnalyzer\n\nif __name__ == \"__main__\":\n    configs = {\n        \"ocr\": {\n            \"text_detector\": {\n                \"device\": \"cuda\",\n            },\n            \"text_recognizer\": {\n                \"device\": \"cuda\",\n            },\n        },\n        \"layout_analyzer\": {\n            \"layout_parser\": {\n                \"device\": \"cpu\",\n            },\n            \"table_structure_recognizer\": {\n                \"device\": \"cpu\",\n            },\n        },\n    }\n\n    DocumentAnalyzer(configs=configs)\n</code></pre>"},{"location":"module/#yaml","title":"yaml \u30d5\u30a1\u30a4\u30eb\u3067\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u5b9a\u7fa9","text":"<p>Config \u306b yaml \u30d5\u30a1\u30a4\u30eb\u306e\u30d1\u30b9\u3092\u4e0e\u3048\u308b\u3053\u3068\u3067\u3001\u63a8\u8ad6\u6642\u306e\u7d30\u90e8\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u8abf\u6574\u304c\u53ef\u80fd\u3067\u3059\u3002yaml \u30d5\u30a1\u30a4\u30eb\u306e\u4f8b\u306f\u30ea\u30dd\u30b8\u30c8\u30ea\u5185\u306e<code>configs</code>\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u5185\u306b\u3042\u308a\u307e\u3059\u3002\u30e2\u30c7\u30eb\u306e\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u306f\u5909\u66f4\u3067\u304d\u307e\u305b\u3093\u304c\u3001\u5f8c\u51e6\u7406\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3084\u5165\u529b\u753b\u50cf\u306e\u30b5\u30a4\u30ba\u306a\u3069\u306f\u4e00\u90e8\u5909\u66f4\u304c\u53ef\u80fd\u3067\u3059\u3002\u5909\u66f4\u53ef\u80fd\u306a\u30d1\u30e9\u30e1\u30fc\u30bf\u306fconfiguration\u3092\u53c2\u8003\u306b\u3057\u3066\u304f\u3060\u3055\u3044\u3002</p> <p>\u305f\u3068\u3048\u3070\u3001\u4ee5\u4e0b\u306e\u3088\u3046\u306b<code>Text Detector</code>\u306e\u5f8c\u51e6\u7406\u306e\u95be\u5024\u3092 yaml \u3092\u5b9a\u7fa9\u3057\u3001config \u306b\u30d1\u30b9\u3092\u8a2d\u5b9a\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002config \u30d5\u30a1\u30a4\u30eb\u306f\u3059\u3079\u3066\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u8a18\u8f09\u3059\u308b\u5fc5\u8981\u306f\u306a\u304f\u3001\u5909\u66f4\u304c\u5fc5\u8981\u306a\u30d1\u30e9\u30e1\u30fc\u30bf\u306e\u307f\u306e\u8a18\u8f09\u304c\u53ef\u80fd\u3067\u3059\u3002</p> <p><code>text_detector.yaml</code>\u306e\u8a18\u8ff0</p> <pre><code>post_process:\n  thresh: 0.1\n  unclip_ratio: 2.5\n</code></pre> <p>yaml \u30d5\u30a1\u30a4\u30eb\u306e\u30d1\u30b9\u3092 config \u306b\u683c\u7d0d\u3059\u308b</p> demo/setting_document_anaysis.py <pre><code>from yomitoku import DocumentAnalyzer\n\n\n\nif __name__ == \"__main__\":\n\n    configs = {\"ocr\": {\"text_detector\": {\"path_cfg\": \"demo/text_detector.yaml\"}}}\n\n\n\n    analyzer = DocumentAnalyzer(configs=configs, visualize=True, device=\"cuda\")\n</code></pre>"},{"location":"module/#_3","title":"\u30a4\u30f3\u30bf\u30fc\u30cd\u30c3\u30c8\u306b\u63a5\u7d9a\u3067\u304d\u306a\u3044\u74b0\u5883\u3067\u306e\u5229\u7528","text":"<p>Yomitoku \u306f\u521d\u56de\u306e\u5b9f\u884c\u6642\u306b HuggingFaceHub \u304b\u3089\u30e2\u30c7\u30eb\u3092\u81ea\u52d5\u3067\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u307e\u3059\u3002\u305d\u306e\u969b\u306b\u30a4\u30f3\u30bf\u30fc\u30cd\u30c3\u30c8\u74b0\u5883\u304c\u5fc5\u8981\u3067\u3059\u304c\u3001\u4e8b\u524d\u306b\u624b\u52d5\u3067\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3059\u308b\u3053\u3068\u3067\u30a4\u30f3\u30bf\u30fc\u30cd\u30c3\u30c8\u306b\u63a5\u7d9a\u3067\u304d\u306a\u3044\u74b0\u5883\u3067\u3082\u5b9f\u884c\u3059\u308b\u3053\u3068\u304c\u53ef\u80fd\u3067\u3059\u3002</p> <pre><code>download_model\n</code></pre> <p>\u5b9f\u884c\u6642\u306b\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3055\u308c\u305f\u30ea\u30dd\u30b8\u30c8\u30ea\u306e\u30d5\u30a9\u30eb\u30c0<code>KotaroKinoshita</code>\u3092\u30ab\u30ec\u30f3\u30c8\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u914d\u7f6e\u3059\u308b\u3053\u3068\u3067\u3001\u30a4\u30f3\u30bf\u30fc\u30cd\u30c3\u30c8\u3078\u306e\u63a5\u7d9a\u306a\u3057\u306b\u3001\u30ed\u30fc\u30ab\u30eb\u30ea\u30dd\u30b8\u30c8\u30ea\u306e\u30e2\u30c7\u30eb\u304c\u547c\u3073\u51fa\u3055\u308c\u5b9f\u884c\u3055\u308c\u307e\u3059\u3002</p>"},{"location":"ocr_schema/","title":"OCR","text":"OCRSchema OCRSchemaType: object No Additional Properties words Required root          wordsWordsType: array <p>List of recognized words with their bounding boxes, content, direction, and scores</p> No Additional ItemsEach item of this array must be: root          words WordPredictionWordPredictionType: object No Additional Properties points Required root          words WordPrediction pointsPointsType: array of array <p>Bounding box of the word in the format [[x1, y1], [x2, y2], [x3, y3], [x4, y4]]</p> <p>Must contain a minimum of <code>4</code> items</p><p>Must contain a maximum of <code>4</code> items</p> No Additional ItemsEach item of this array must be: root          words WordPrediction points points itemsType: array of integer <p>Must contain a minimum of <code>2</code> items</p><p>Must contain a maximum of <code>2</code> items</p> No Additional ItemsEach item of this array must be: root          words WordPrediction points points items points items itemsType: integer content Required root          words WordPrediction contentContentType: string <p>Text content of the word</p> direction Required root          words WordPrediction directionDirectionType: string <p>Text direction, e.g., 'horizontal' or 'vertical'</p> rec_score Required root          words WordPrediction rec_scoreRec ScoreType: number <p>Confidence score of the word recognition</p> det_score Required root          words WordPrediction det_scoreDet ScoreType: number <p>Confidence score of the word detection</p> <p>Generated using json-schema-for-humans on 2025-07-30 at 10:57:58 +0900</p>"},{"location":"release_note/","title":"Release Note","text":""},{"location":"release_note/#changelog","title":"Changelog","text":""},{"location":"release_note/#v094-2025-06-12","title":"v0.9.4 (2025-06-12)","text":"<p>Full Changelog</p>"},{"location":"release_note/#v093-2025-06-05","title":"v0.9.3 (2025-06-05)","text":"<p>Full Changelog</p>"},{"location":"release_note/#v092post1-2025-06-05","title":"v0.9.2.post1 (2025-06-05)","text":"<p>Full Changelog</p>"},{"location":"release_note/#v092-2025-06-05","title":"v0.9.2 (2025-06-05)","text":"<p>Full Changelog</p>"},{"location":"release_note/#v091-2025-05-16","title":"v0.9.1 (2025-05-16)","text":"<p>Full Changelog</p>"},{"location":"release_note/#v090-2025-04-18","title":"v0.9.0 (2025-04-18)","text":"<p>Full Changelog</p>"},{"location":"release_note/#v081-2025-04-03","title":"v0.8.1 (2025-04-03)","text":"<p>Full Changelog</p>"},{"location":"release_note/#v080-2025-04-03","title":"v0.8.0 (2025-04-03)","text":"<p>Full Changelog</p>"},{"location":"release_note/#v074-2025-04-03","title":"v0.7.4 (2025-04-03)","text":"<p>Full Changelog</p>"},{"location":"release_note/#v073-2025-03-20","title":"v0.7.3 (2025-03-20)","text":"<p>Full Changelog</p>"},{"location":"release_note/#v072-2025-02-21","title":"v0.7.2 (2025-02-21)","text":"<p>Full Changelog</p>"},{"location":"release_note/#v071-2025-01-04","title":"v0.7.1 (2025-01-04)","text":"<p>Full Changelog</p>"},{"location":"release_note/#v070-2024-12-31","title":"v0.7.0 (2024-12-31)","text":"<p>Full Changelog</p>"},{"location":"release_note/#v060-2024-12-15","title":"v0.6.0 (2024-12-15)","text":"<p>Full Changelog</p>"},{"location":"release_note/#v053-2024-12-05","title":"v0.5.3 (2024-12-05)","text":"<p>Full Changelog</p>"},{"location":"release_note/#v052-2024-11-28","title":"v0.5.2 (2024-11-28)","text":"<p>Full Changelog</p>"},{"location":"release_note/#v051-2024-11-26","title":"v0.5.1 (2024-11-26)","text":"<p>Full Changelog</p>"},{"location":"release_note/#v050-2024-11-26","title":"v0.5.0 (2024-11-26)","text":"<p>Full Changelog</p>"},{"location":"release_note/#v041-2024-11-25","title":"v0.4.1 (2024-11-25)","text":"<p>Full Changelog</p>"},{"location":"release_note/#v040-2024-11-25","title":"v0.4.0 (2024-11-25)","text":"<p>Full Changelog</p>"},{"location":"release_note/#v030-2024-11-19","title":"v0.3.0 (2024-11-19)","text":"<p>Full Changelog</p>"},{"location":"release_note/#v020-2024-11-16","title":"v0.2.0 (2024-11-16)","text":"<p>Full Changelog</p>"},{"location":"release_note/#v010-2024-10-30","title":"v0.1.0 (2024-10-30)","text":"<p>Full Changelog</p> <p>* This Changelog was automatically generated by github_changelog_generator</p>"},{"location":"en/cli/","title":"CLI Usage","text":"<p>The model weight files are downloaded from Hugging Face Hub only during the first execution.</p> <pre><code>yomitoku ${path_data} -v -o results\n</code></pre> <ul> <li><code>${path_data}</code>: Specify the path to a directory containing images to be analyzed or directly provide the path to an image file. If a directory is specified, images in its subdirectories will also be processed.</li> <li><code>-f</code>, <code>--format</code>: Specify the output file format. Supported formats are json, csv, html, md , and pdf(searchable-pdf).</li> <li><code>-o</code>, <code>--outdir</code>: Specify the name of the output directory. If it does not exist, it will be created.</li> <li><code>-v</code>, <code>--vis</code>: If specified, outputs visualized images of the analysis results.</li> </ul> <p>NOTE</p> <ul> <li>Only printed text recognition is supported. While it may occasionally read handwritten text, official support is not provided.</li> <li>YomiToku is optimized for document OCR and is not designed for scene OCR (e.g., text printed on non-paper surfaces like signs).</li> <li>The resolution of input images is critical for improving the accuracy of AI-OCR recognition. Low-resolution images may lead to reduced recognition accuracy. It is recommended to use images with a minimum short side resolution of 720px for inference.</li> </ul>"},{"location":"en/cli/#reference-for-help","title":"Reference for Help","text":"<p>Displays the options available for the CLI using \u3000<code>--help</code>, <code>-h</code></p> <pre><code>yomitoku -h\n</code></pre>"},{"location":"en/cli/#running-in-lightweight-mode","title":"Running in Lightweight Mode","text":"<p>By using the --lite option, it is possible to perform inference with a lightweight model. This enables faster analysis compared to the standard mode. However, the accuracy of character recognition may decrease.</p> <pre><code>yomitoku ${path_data} --lite -v\n</code></pre>"},{"location":"en/cli/#specifying-output-format","title":"Specifying Output Format","text":"<p>You can specify the output format of the analysis results using the --format or -f option. Supported output formats include JSON, CSV, HTML, and MD (Markdown).</p> <pre><code>yomitoku ${path_data} -f md\n</code></pre> <ul> <li><code>pdf</code>: Detect the text in the image and embed it into the PDF as invisible text, converting the file into a searchable PDF.</li> </ul>"},{"location":"en/cli/#specifying-the-output-device","title":"Specifying the Output Device","text":"<p>You can specify the device for running the model using the -d or --device option. Supported options are cuda, cpu, and mps. If a GPU is not available, inference will be performed on the CPU. (Default: cuda)</p> <pre><code>yomitoku ${path_data} -d cpu\n</code></pre>"},{"location":"en/cli/#ignoring-line-breaks","title":"Ignoring Line Breaks","text":"<p>In the normal mode, line breaks are applied based on the information described in the image. By using the --ignore_line_break option, you can ignore the line break positions in the image and return the same sentence within a paragraph as a single connected output.</p> <pre><code>yomitoku ${path_data} --ignore_line_break\n</code></pre>"},{"location":"en/cli/#outputting-figures-and-graph-images","title":"Outputting Figures and Graph Images","text":"<p>In the normal mode, information about figures or images contained in document images is not output. By using the --figure option, you can extract figures and images included in the document image, save them as separate image files, and include links to the detected individual images in the output file.</p> <pre><code>yomitoku ${path_data} --figure\n</code></pre>"},{"location":"en/cli/#outputting-text-contained-in-figures-and-images","title":"Outputting Text Contained in Figures and Images","text":"<p>In normal mode, text information contained within figures or images is not included in the output file. By using the --figure_letter option, text information within figures and images will also be included in the output file.</p> <pre><code>yomitoku ${path_data} --figure_letter\n</code></pre>"},{"location":"en/cli/#specifying-the-character-encoding-of-the-output-file","title":"Specifying the Character Encoding of the Output File","text":"<p>You can specify the character encoding of the output file using the --encoding option. Supported encodings include <code>utf-8</code>, <code>utf-8-sig</code>, <code>shift-jis</code>, <code>enc-jp</code>, and <code>cp932</code>. If unsupported characters are encountered, they will be ignored and not included in the output.</p> <pre><code>yomitoku ${path_data} --encoding utf-8-sig\n</code></pre>"},{"location":"en/cli/#specifying-the-path-to-config-files","title":"Specifying the Path to Config Files","text":"<p>Specify the path to the config files for each module as follows:</p> <ul> <li><code>--td_cfg</code>: Path to the YAML file containing the config for the Text Detector</li> <li><code>--tr_cfg</code>: Path to the YAML file containing the config for the Text Recognizer</li> <li><code>--lp_cfg</code>: Path to the YAML file containing the config for the Layout Parser</li> <li><code>--tsr_cfg</code>: Path to the YAML file containing the config for the Table Structure Recognizer</li> </ul> <pre><code>yomitoku ${path_data} --td_cfg ${path_yaml}\n</code></pre>"},{"location":"en/cli/#do-not-include-metadata-in-the-output-file","title":"Do not include metadata in the output file","text":"<p>You can exclude metadata such as headers and footers from the output file. <pre><code>yomitoku ${path_data} --ignore_meta\n</code></pre></p>"},{"location":"en/cli/#combine-multiple-pages","title":"Combine multiple pages","text":"<p>If the PDF contains multiple pages, you can export them as a single file.</p> <pre><code>yomitoku ${path_data} -f md --combine\n</code></pre>"},{"location":"en/cli/#setting-the-pdf-reading-resolution","title":"Setting the PDF Reading Resolution","text":"<p>Specifies the resolution (DPI) when reading a PDF (default DPI = 200). Increasing the DPI value may improve recognition accuracy when dealing with fine text or small details within the PDF.</p> <pre><code>yomitoku ${path_data} --dpi 250\n</code></pre>"},{"location":"en/cli/#specifying-reading-order","title":"Specifying Reading Order","text":"<p>By default, Auto mode automatically detects whether a document is written horizontally or vertically and estimates the appropriate reading order. However, you can explicitly specify a custom reading order. For horizontal documents, the default is <code>top2left</code>, and for vertical documents, it is <code>top2bottom</code>.</p> <pre><code>yomitoku ${path_data} --reading_order left2right\n</code></pre> <ul> <li> <p><code>top2bottom</code>: Prioritizes reading from top to bottom. Useful for multi-column documents such as word processor files with vertical flow.</p> </li> <li> <p><code>left2right</code>: Prioritizes reading from left to right. Suitable for layouts like receipts or health insurance cards, where key-value text pairs are arranged in columns.</p> </li> <li> <p><code>right2left</code>: Prioritizes reading from right to left. Effective for vertically written documents.</p> </li> </ul>"},{"location":"en/cli/#specifying-pages-to-process","title":"Specifying Pages to Process","text":"<p>You can choose to process only specific pages. Pages can be specified either as a comma-separated list or as a range using a hyphen.</p> <pre><code>yomitoku ${path_data} --pages 1,3-5,10\n</code></pre>"},{"location":"en/configuration/","title":"Configuration","text":"<p>The configurable parameters for each module are explained.</p>"},{"location":"en/configuration/#input-data","title":"input data","text":"<pre><code>data:\n  # If the number of pixels on the shorter side of the image falls below the specified value, the image will be enlarged to ensure that it meets or exceeds the pixel count set here.\n  shortest_size: int \n\n  # If the number of pixels on the longer side of the image exceeds the specified value, the image will be resized to ensure that it is equal to or less than the pixel count set here.\n  limit_size: int \n</code></pre>"},{"location":"en/configuration/#post-process","title":"post process","text":"<pre><code>post_process:\n  #If the size of the larger side of the detected area falls below the specified value, the area will be removed.\n  min_size: int \n\n  # This is the threshold for the model's prediction score. Pixels with prediction scores below the specified threshold will be treated as background regions.\n  thresh: float \n\n  # The threshold for the model's prediction score is used to treat pixels with prediction scores below the specified threshold as background regions.\n  box_thresh: float \n\n  # The maximum number of detectable text regions.\n  max_candidates: int \n\n  # A parameter to set the size of the margin area for text regions. Larger values increase the margin around text regions, allowing for detection with more whitespace, while smaller values result in tighter detection.\n  unclip_ratio: int \n\n### Visualization\n\n```yaml\nvisualize:\n  # The color of the bounding box for the detected regions.\n  color: [B, G, R] \n\n  # Whether to visualize and render the model's prediction heatmap.\n  heatmap: boolean \n</code></pre>"},{"location":"en/configuration/#maximum-text-length","title":"maximum text length","text":"<pre><code># The maximum string length that can be predicted. \nmax_label_length: int \n</code></pre>"},{"location":"en/configuration/#input-data_1","title":"input data","text":"<pre><code>data:\n  # The number of images used for batch processing.\n  batch_size: int \n</code></pre>"},{"location":"en/configuration/#visualization","title":"visualization","text":"<pre><code>visualize:\n  # The path to the font used for visualizing the predicted result strings.\n  font: str \n\n  # The color of the font used for visualizing the predicted result strings.\n  color: [BGR]\n\n  # The font size of the predicted result strings.\n  font_size: int \n</code></pre>"},{"location":"en/configuration/#threshold-of-prediction-score","title":"threshold of prediction score","text":"<pre><code># Regions with prediction scores below the specified threshold will be excluded based on the threshold for the model's prediction score.\nthresh_score: float \n</code></pre>"},{"location":"en/configuration/#threshold-of-prediction-score_1","title":"threshold of prediction score","text":"<pre><code># Regions with prediction scores below the specified threshold will be excluded based on the threshold for the model's prediction score.\nthresh_score: float\n</code></pre>"},{"location":"en/#introduction","title":"\ud83c\udf1f Introduction","text":"<p>YomiToku is a Document AI engine specialized in Japanese document image analysis. It provides full OCR (optical character recognition) and layout analysis capabilities, enabling the recognition, extraction, and conversion of text and diagrams from images.</p> <ul> <li>\ud83e\udd16 Equipped with four AI models trained on Japanese datasets: text detection, text recognition, layout analysis, and table structure recognition. All models are independently trained and optimized for Japanese documents, delivering high-precision inference.</li> <li>\ud83c\uddef\ud83c\uddf5 Each model is specifically trained for Japanese document images, supporting the recognition of over 7,000 Japanese characters, including vertical text and other layout structures unique to Japanese documents. (It also supports English documents.)</li> <li>\ud83d\udcc8 By leveraging layout analysis, table structure parsing, and reading order estimation, it extracts information while preserving the semantic structure of the document layout.</li> <li>\ud83d\udcc4 Supports a variety of output formats, including HTML, Markdown, JSON, and CSV. It also allows for the extraction of diagrams and images contained within the documents.It also supports converting document images into fully text-searchable PDFs.</li> <li>\u26a1 Operates efficiently in GPU environments, enabling fast document transcription and analysis. It requires less than 8GB of VRAM, eliminating the need for high-end GPUs.\u3002</li> </ul>"},{"location":"en/#q-is-it-possible-to-use-yomitoku-in-an-environment-without-internet-access","title":"Q. Is it possible to use YomiToku in an environment without internet access?","text":"<p>A. Yes, it is possible. YomiToku connects to Hugging Face Hub to automatically download model files during the first execution, requiring internet access at that time. However, you can manually download the files in advance, allowing YomiToku to operate in an offline environment. For details, please refer to Module Usage under the section \"Using YomiToku in an Offline Environment.\"</p>"},{"location":"en/#q-is-commercial-use-allowed","title":"Q. Is commercial use allowed?","text":"<p>A. This package is licensed under CC BY-NC 4.0. It is available for free for personal and research purposes. For commercial use, a paid commercial license is required. Please contact the developers for further details.</p>"},{"location":"en/installation/","title":"Installation","text":"<p>This package requires Python 3.10 or later and PyTorch 2.5 or later for execution. PyTorch must be installed according to your CUDA version. A GPU with more than 8GB of VRAM is recommended. While it can run on a CPU, please note that the processing is not currently optimized for CPUs, which may result in longer execution times.</p>"},{"location":"en/installation/#from-pypi","title":"from PYPI","text":"<pre><code>pip install yomitoku\n</code></pre>"},{"location":"en/installation/#using-uv","title":"using uv","text":"<p>This repository uses the package management tool uv. After installing uv, clone the repository and execute the following commands:</p> <pre><code>uv sync\n</code></pre> <p>Using GPU with onnxruntime <pre><code>uv sync --extra gpu\n</code></pre></p> <p>When using uv, you need to modify the following part of the pyproject.toml file to match your CUDA version. By default, PyTorch compatible with CUDA 12.4 will be downloaded.</p> <pre><code>[[tool.uv.index]]\nname = \"pytorch-cuda124\"\nurl = \"https://download.pytorch.org/whl/cu124\"\nexplicit = true\n</code></pre>"},{"location":"en/installation/#using-docker","title":"using docker","text":"<p>A Dockerfile is provided in the root of the repository, which you are welcome to use.</p> <pre><code>docker build -t yomitoku .\n</code></pre> GPUCPU <pre><code>docker run -it --gpus all -v $(pwd):/workspace --name yomitoku yomitoku /bin/bash\n</code></pre> <pre><code>docker run -it -v $(pwd):/workspace --name yomitoku yomitoku /bin/bash\n</code></pre>"},{"location":"en/mcp/","title":"MCP","text":"<p>This section explains how to use the Yomitoku MCP server in conjunction with Claude Desktop.</p>"},{"location":"en/mcp/#installing-yomitoku","title":"Installing Yomitoku","text":"<p>First, install Yomitoku by following the \"Installation with uv\" section in Installation.</p> <p>However, to add <code>mcp</code> as a dependency during installation, include <code>mcp</code> in <code>--extra</code> as shown below.</p> <pre><code>uv sync --extra mcp\n</code></pre>"},{"location":"en/mcp/#setting-up-claude-desktop","title":"Setting up Claude Desktop","text":"<p>Next, add the following configuration to the <code>mcpServers</code> section of the Claude Desktop configuration file. (Refer to here for how to open the configuration file)</p> <pre><code>{\n  \"mcpServers\": {\n    \"yomitoku\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"(Absolute path of the directory where Yomitoku was cloned)\",\n        \"run\",\n        \"yomitoku_mcp\"\n      ],\n      \"env\": {\n        \"RESOURCE_DIR\": \"(Absolute path of the directory containing files for OCR)\"\n      }\n    }\n  }\n}\n</code></pre> <p>For example, if you executed <code>git clone https://github.com/kotaro-kinoshita/yomitoku.git</code> in <code>/Users/your-username/workspace</code>, then <code>(Directory where Yomitoku was cloned)</code> would be <code>/Users/your-username/workspace/yomitoku</code>, and if you use <code>sample.pdf</code> in the <code>yomitoku/demo</code> directory, specify <code>(Directory containing files for OCR)</code> as <code>/Users/your-username/workspace/yomitoku/demo</code>.</p>"},{"location":"en/mcp/#using-claude-desktop","title":"Using Claude Desktop","text":"<ul> <li>Please restart Claude Desktop to apply changes to the configuration file.</li> </ul> <p>For example, if you use <code>yomitoku/demo/sample.pdf</code> as a sample, instruct as follows:</p> <pre><code>Analyze sample.pdf using OCR and translate it into English.\n</code></pre>"},{"location":"en/mcp/#starting-the-sse-server","title":"Starting the SSE Server","text":"<p>Set the path to the folder containing the images to be processed by OCR in the resource directory.</p> <pre><code>export RESOURCE_DIR=\"path of dataset\"\n</code></pre> <p>Start the SSE server using the following command:</p> <pre><code>uv run yomitoku_mcp -t sse\n</code></pre> <p>The SSE server endpoint will be available at <code>http://127.0.0.1:8000/sse</code>.</p>"},{"location":"en/module/","title":"Calling from within Python code","text":""},{"location":"en/module/#document-analyzer","title":"Document Analyzer \u306e\u5229\u7528","text":"<p>The Document Analyzer performs OCR and layout analysis, integrating these results into a comprehensive analysis output. It can be used for various use cases, including paragraph and table structure analysis, extraction, and figure/table detection.</p> demo/simple_document_analysis.py <pre><code>import cv2\n\n\n\nfrom yomitoku import DocumentAnalyzer\n\nfrom yomitoku.data.functions import load_pdf\n\n\n\nif __name__ == \"__main__\":\n\n    PATH_IMGE = \"demo/sample.pdf\"\n\n    analyzer = DocumentAnalyzer(visualize=True, device=\"cuda\")\n\n    # PDF\u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u307f\u8fbc\u307f\n\n    imgs = load_pdf(PATH_IMGE)\n\n    for i, img in enumerate(imgs):\n\n        results, ocr_vis, layout_vis = analyzer(img)\n\n        # HTML\u5f62\u5f0f\u3067\u89e3\u6790\u7d50\u679c\u3092\u30a8\u30af\u30b9\u30dd\u30fc\u30c8\n\n        results.to_html(f\"output_{i}.html\", img=img)\n\n        # \u53ef\u8996\u5316\u753b\u50cf\u3092\u4fdd\u5b58\n\n        cv2.imwrite(f\"output_ocr_{i}.jpg\", ocr_vis)\n\n        cv2.imwrite(f\"output_layout_{i}.jpg\", layout_vis)\n</code></pre> <ul> <li>Setting <code>visualize</code> to True enables the visualization of each processing result. The second and third return values will contain the OCR and layout analysis results, respectively. If set to False, None will be returned. Since visualization adds computational overhead, it is recommended to set it to False unless needed for debugging purposes.</li> <li>The <code>device</code> parameter specifies the computation device to be used. The default is \"cuda\". If a GPU is unavailable, it automatically switches to CPU mode for processing.</li> <li>The <code>configs</code> parameter allows you to set more detailed parameters for the pipeline processing.</li> </ul> <p>The results of DocumentAnalyzer can be exported in the following formats:</p> <p><code>to_json()</code>: JSON format (.json) <code>to_html()</code>: HTML format (.html) <code>to_csv()</code>: Comma-separated CSV format (.csv) <code>to_markdown()</code>: Markdown format (.md)</p>"},{"location":"en/module/#using-ai-ocr-only","title":"Using AI-OCR Only","text":"<p>AI-OCR performs text detection and recognition on the detected text, returning the positions of the text within the image along with the</p> demo/simple_ocr.py <pre><code>import cv2\n\n\n\nfrom yomitoku import OCR\n\nfrom yomitoku.data.functions import load_pdf\n\n\n\nif __name__ == \"__main__\":\n\n    ocr = OCR(visualize=True, device=\"cuda\")\n\n    # PDF\u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u307f\u8fbc\u307f\n\n    imgs = load_pdf(\"demo/sample.pdf\")\n\n    import time\n\n\n\n    start = time.time()\n\n    for i, img in enumerate(imgs):\n\n        results, ocr_vis = ocr(img)\n\n\n\n        # JSON\u5f62\u5f0f\u3067\u89e3\u6790\u7d50\u679c\u3092\u30a8\u30af\u30b9\u30dd\u30fc\u30c8\n\n        results.to_json(f\"output_{i}.json\")\n\n        cv2.imwrite(f\"output_ocr_{i}.jpg\", ocr_vis)\n</code></pre> <ul> <li>Setting <code>visualize</code> to True enables the visualization of each processing result. The second and third return values will contain the OCR and layout analysis results, respectively. If set to False, None will be returned. Since visualization adds computational overhead, it is recommended to set it to False unless needed for debugging purposes.</li> <li>The <code>device</code> parameter specifies the computation device to be used. The default is \"cuda\". If a GPU is unavailable, it automatically switches to CPU mode for processing.</li> <li>The <code>configs</code> parameter allows you to set more detailed parameters for the pipeline processing.</li> </ul> <p>The results of OCR processing support export in JSON format (<code>to_json()</code>) only.</p>"},{"location":"en/module/#using-layout-analyzer-only","title":"Using Layout Analyzer only","text":"<p>The <code>LayoutAnalyzer</code> performs text detection, followed by AI-based paragraph, figure/table detection, and table structure analysis. It analyzes the layout structure within the document.</p> demo/simple_layout.py <pre><code>import cv2\n\n\n\nfrom yomitoku import LayoutAnalyzer\n\nfrom yomitoku.data.functions import load_pdf\n\n\n\nif __name__ == \"__main__\":\n\n    analyzer = LayoutAnalyzer(visualize=True, device=\"cuda\")\n\n    # PDF\u30d5\u30a1\u30a4\u30eb\u3092\u8aad\u307f\u8fbc\u307f\n\n    imgs = load_pdf(\"demo/sample.pdf\")\n\n    for i, img in enumerate(imgs):\n\n        results, layout_vis = analyzer(img)\n\n\n\n        # JSON\u5f62\u5f0f\u3067\u89e3\u6790\u7d50\u679c\u3092\u30a8\u30af\u30b9\u30dd\u30fc\u30c8\n\n        results.to_json(f\"output_{i}.json\")\n\n        cv2.imwrite(f\"output_layout_{i}.jpg\", layout_vis)\n</code></pre> <ul> <li>Setting <code>visualize</code> to True enables the visualization of each processing result. The second and third return values will contain the OCR and layout analysis results, respectively. If set to False, None will be returned. Since visualization adds computational overhead, it is recommended to set it to False unless needed for debugging purposes.</li> <li>The <code>device</code> parameter specifies the computation device to be used. The default is <code>cuda</code>. If a GPU is unavailable, it automatically switches to CPU mode for processing.</li> <li>The <code>configs</code> parameter allows you to set more detailed parameters for the pipeline processing.</li> </ul> <p>The results of LayoutAnalyzer processing support export only in JSON format (to_json()).</p>"},{"location":"en/module/#detailed-configuration-of-the-pipeline","title":"Detailed Configuration of the Pipeline","text":"<p>By providing a config, you can adjust the behavior in greater detail.</p> <ul> <li>model_name: Specifies the architecture of the model to be used.</li> <li>path_cfg: Provides the path to the config file containing hyperparameters.</li> <li>device: Specifies the device to be used for inference. Options are <code>cuda</code>, <code>cpu</code>, or <code>mps</code>.</li> <li>visualize: Indicates whether to perform visualization of the processing results (boolean).</li> <li>from_pretrained: Specifies whether to use a pretrained model (boolean).</li> <li>infer_onnx: Indicates whether to use onnxruntime for inference instead of PyTorch (boolean).</li> </ul> <p>Supported Model Types (model_name)</p> <ul> <li>TextRecognizer: <code>parseq</code>, <code>parseq-small</code></li> <li>TextDetector: <code>dbnet</code></li> <li>LayoutParser: <code>rtdetrv2</code></li> <li>TableStructureRecognizer: <code>rtdetrv2</code></li> </ul>"},{"location":"en/module/#how-to-write-config","title":"How to Write Config","text":"<p>The config is provided in dictionary format. By using a config, you can execute processing on different devices for each module and set detailed parameters. For example, the following config allows the OCR processing to run on a GPU, while the layout analysis is performed on a CPU:</p> <pre><code>from yomitoku import DocumentAnalyzer\n\nif __name__ == \"__main__\":\n    configs = {\n        \"ocr\": {\n            \"text_detector\": {\n                \"device\": \"cuda\",\n            },\n            \"text_recognizer\": {\n                \"device\": \"cuda\",\n            },\n        },\n        \"layout_analyzer\": {\n            \"layout_parser\": {\n                \"device\": \"cpu\",\n            },\n            \"table_structure_recognizer\": {\n                \"device\": \"cpu\",\n            },\n        },\n    }\n\n    DocumentAnalyzer(configs=configs)\n</code></pre>"},{"location":"en/module/#defining-parameters-in-an-yaml-file","title":"Defining Parameters in an YAML File","text":"<p>By providing the path to a YAML file in the config, you can adjust detailed parameters for inference. Examples of YAML files can be found in the <code>configs</code> directory within the repository. While the model's network parameters cannot be modified, certain aspects like post-processing parameters and input image size can be adjusted.Refer to configuration for configurable parameters.</p> <p>For instance, you can define post-processing thresholds for the Text Detector in a YAML file and set its path in the config. The config file does not need to include all parameters; you only need to specify the parameters that require changes.</p> <pre><code>post_process:\n  thresh: 0.1\n  unclip_ratio: 2.5\n</code></pre> <p>Storing the Path to a YAML File in the Config</p> demo/setting_document_anaysis.py <pre><code>from yomitoku import DocumentAnalyzer\n\n\n\nif __name__ == \"__main__\":\n\n    configs = {\"ocr\": {\"text_detector\": {\"path_cfg\": \"demo/text_detector.yaml\"}}}\n\n\n\n    analyzer = DocumentAnalyzer(configs=configs, visualize=True, device=\"cuda\")\n</code></pre>"},{"location":"en/module/#using-yomitoku-in-offline-environments","title":"Using Yomitoku in Offline Environments","text":"<p>Yomitoku automatically downloads the model from Hugging Face Hub on its first run. An internet connection is required at that time, but by manually downloading the model beforehand, you can also run Yomitoku in environments without internet access.</p> <pre><code>download_model\n</code></pre> <p>By placing the downloaded repository folder <code>KotaroKinoshita</code> in the current directory at runtime, the local repository model will be loaded and executed without any internet connection.</p>"}]}